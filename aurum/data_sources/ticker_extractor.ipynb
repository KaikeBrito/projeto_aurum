{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18dcd3f",
   "metadata": {},
   "source": [
    "### üìÑ Documenta√ß√£o: Extrator de Composi√ß√£o IBRX-100 (API B3)\n",
    "\n",
    "### 1. Vis√£o Geral\n",
    "\n",
    "Este script √© um componente de **Extra√ß√£o (E)** dentro do pipeline ETL do projeto Aurum. Sua fun√ß√£o √© conectar-se diretamente √† API \"oculta\" da B3 (Brasil, Bolsa, Balc√£o) para obter a carteira te√≥rica atualizada do √≠ndice **IBRX-100**.\n",
    "\n",
    "Diferente de abordagens tradicionais que utilizam *web scraping* (Selenium/BeautifulSoup), este script utiliza engenharia reversa da chamada de API da B3, codificando par√¢metros em Base64 para simular uma requisi√ß√£o leg√≠tima do navegador.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Depend√™ncias T√©cnicas\n",
    "\n",
    "Para executar este script, o ambiente Python deve conter as seguintes bibliotecas:\n",
    "\n",
    "* **pandas:** Manipula√ß√£o e estrutura√ß√£o dos dados.\n",
    "* **requests:** Realiza√ß√£o de chamadas HTTP √† API.\n",
    "* **urllib3:** Gerenciamento de conex√µes e supress√£o de avisos SSL.\n",
    "* **Bibliotecas Padr√£o:** `json`, `base64`, `logging`, `pathlib`, `time`.\n",
    "\n",
    "### 3. Estrutura do Script\n",
    "\n",
    "O script n√£o utiliza Classes (POO), mas sim uma arquitetura funcional modular. Abaixo est√£o as descri√ß√µes das principais fun√ß√µes:\n",
    "\n",
    "### **fetch_ibrx100_from_b3_api()**\n",
    "\n",
    "Esta √© a fun√ß√£o \"core\" do extrator.\n",
    "\n",
    "1. **Prepara Par√¢metros:** Define um dicion√°rio JSON com o √≠ndice alvo (`IBXX` para IBRX-100) e pagina√ß√£o.\n",
    "2. **Codifica√ß√£o Base64:** Transforma o JSON em uma string Base64, replicando o comportamento do frontend da B3.\n",
    "3. **Requisi√ß√£o:** Envia um GET para o endpoint `indexProxy/indexCall/GetPortfolioDay`.\n",
    "4. **Tratamento de Dados:**\n",
    "    * Consome o JSON de resposta.\n",
    "    * **Autocorre√ß√£o de Colunas:** Verifica dinamicamente o nome da coluna de c√≥digo do ativo (`codNeg`, `cod`, `acronym`), garantindo robustez caso a B3 altere a API.\n",
    "    * **Normaliza√ß√£o:** Remove espa√ßos em branco e cria a coluna compat√≠vel com o Yahoo Finance (sufixo `.SA`).\n",
    "\n",
    "\n",
    "\n",
    "### `save_data(df)`\n",
    "\n",
    "Respons√°vel pela persist√™ncia dos dados.\n",
    "\n",
    "1. Verifica se o diret√≥rio `../data` existe; caso contr√°rio, cria-o.\n",
    "2. Salva o DataFrame em dois formatos:\n",
    "    * **.CSV:** Para inspe√ß√£o humana e compatibilidade simples.\n",
    "    * **.PARQUET:** Para leitura de alta performance nos pr√≥ximos passos do pipeline.\n",
    "\n",
    "## 4. Dicion√°rio de Dados (Output)\n",
    "\n",
    "O script gera um dataset padronizado. A tabela abaixo descreve o esquema (schema) do arquivo gerado (`tickers_ibrx100_full`).\n",
    "\n",
    "| Nome da Coluna | Tipo de Dado (Pandas) | Descri√ß√£o | Exemplo |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`ticker`** | `object` (string) | O c√≥digo de negocia√ß√£o oficial fornecido pela B3. | `PETR4` |\n",
    "| **`participacao`** | `object` / `float` | (Opcional) A porcentagem de participa√ß√£o do ativo no √≠ndice, se retornada pela API. | `4,520` |\n",
    "| **`Ticker_Yahoo`** | `object` (string) | O ticker normalizado com o sufixo `.SA`, pronto para consumo pela biblioteca `yfinance`. | `PETR4.SA` |\n",
    "\n",
    "## 5. Como Executar\n",
    "\n",
    "Execute o script diretamente via terminal:\n",
    "\n",
    "```bash\n",
    "python b3_api_extractor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 02:00:32,745 - INFO - Iniciando requisi√ß√£o √† API da B3 (IndexProxy)...\n",
      "2025-12-12 02:00:33,723 - INFO - API retornou 97 ativos.\n",
      "2025-12-12 02:00:33,733 - INFO - Colunas encontradas no JSON: ['segment', 'cod', 'asset', 'type', 'part', 'partAcum', 'theoricalQty']\n",
      "2025-12-12 02:00:33,737 - INFO - Coluna de ticker identificada como: 'cod'\n",
      "2025-12-12 02:00:33,744 - INFO - Normalizando tickers (adicionando .SA)...\n",
      "2025-12-12 02:00:33,803 - INFO - üíæ Arquivos salvos:\n",
      "2025-12-12 02:00:33,804 - INFO -    -> ..\\data\\tickers_ibrx100_full.csv\n",
      "2025-12-12 02:00:33,804 - INFO -    -> ..\\data\\tickers_ibrx100_full.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do IBRX-100 (API B3) ---\n",
      "  ticker participacao Ticker_Yahoo\n",
      "0  ALOS3        0,536     ALOS3.SA\n",
      "1  ABEV3        2,359     ABEV3.SA\n",
      "2  ANIM3        0,036     ANIM3.SA\n",
      "3  ASAI3        0,424     ASAI3.SA\n",
      "4  AURE3        0,157     AURE3.SA\n",
      "\n",
      "Tempo total: 1.06 segundos\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import time\n",
    "import urllib3\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "OUTPUT_DIR = Path(\"..\", \"data\") \n",
    "OUTPUT_FILENAME_CSV = \"tickers_ibrx100_full.csv\"\n",
    "OUTPUT_FILENAME_PARQUET = \"tickers_ibrx100_full.parquet\"\n",
    "\n",
    "def fetch_ibrx100_from_b3_api() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Consome diretamente a API JSON da B3 para obter a composi√ß√£o do IBRX-100.\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando requisi√ß√£o √† API da B3 (IndexProxy)...\")\n",
    "    \n",
    "    try:\n",
    "        params = {\n",
    "            \"language\": \"pt-br\",\n",
    "            \"pageNumber\": 1,\n",
    "            \"pageSize\": 120, \n",
    "            \"index\": \"IBXX\", \n",
    "            \"segment\": \"1\"\n",
    "        }\n",
    "        \n",
    "        params_json = json.dumps(params)\n",
    "        params_b64 = base64.b64encode(params_json.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        \n",
    "        url = f\"https://sistemaswebb3-listados.b3.com.br/indexProxy/indexCall/GetPortfolioDay/{params_b64}\"\n",
    "        \n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "        response = requests.get(url, headers=headers, timeout=15, verify=False)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            logger.error(f\"Erro na requisi√ß√£o: Status {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "        data = response.json()\n",
    "        results = data.get('results', [])\n",
    "        \n",
    "        if not results:\n",
    "            logger.warning(\"JSON retornado pela B3 est√° vazio na chave 'results'.\")\n",
    "            return None\n",
    "            \n",
    "        logger.info(f\"API retornou {len(results)} ativos.\")\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        logger.info(f\"Colunas encontradas no JSON: {df.columns.tolist()}\")\n",
    "        \n",
    "        coluna_ticker = None\n",
    "        possiveis_nomes = ['codNeg', 'cod', 'acronym', 'symbol', 'identifier']\n",
    "        \n",
    "        for col in possiveis_nomes:\n",
    "            if col in df.columns:\n",
    "                coluna_ticker = col\n",
    "                logger.info(f\"Coluna de ticker identificada como: '{col}'\")\n",
    "                break\n",
    "        \n",
    "        if not coluna_ticker:\n",
    "            logger.error(\"N√£o foi poss√≠vel identificar a coluna de Ticker no DataFrame.\")\n",
    "            logger.error(f\"Colunas dispon√≠veis: {df.columns.tolist()}\")\n",
    "            return None\n",
    "\n",
    "        coluna_part = 'part' if 'part' in df.columns else None\n",
    "        \n",
    "        colunas_selecao = [coluna_ticker]\n",
    "        if coluna_part:\n",
    "            colunas_selecao.append(coluna_part)\n",
    "            \n",
    "        df_final = df[colunas_selecao].copy()\n",
    "        \n",
    "        rename_map = {coluna_ticker: 'ticker'}\n",
    "        if coluna_part:\n",
    "            rename_map[coluna_part] = 'participacao'\n",
    "            \n",
    "        df_final = df_final.rename(columns=rename_map)\n",
    "        \n",
    "        logger.info(\"Normalizando tickers (adicionando .SA)...\")\n",
    "        df_final['ticker'] = df_final['ticker'].str.strip()\n",
    "        df_final['Ticker_Yahoo'] = df_final['ticker'].apply(lambda x: f\"{x}.SA\")\n",
    "        \n",
    "        return df_final\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Falha cr√≠tica no extrator da API B3: {e}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "def save_data(df: pd.DataFrame):\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    path_csv = OUTPUT_DIR / OUTPUT_FILENAME_CSV\n",
    "    path_parquet = OUTPUT_DIR / OUTPUT_FILENAME_PARQUET\n",
    "    \n",
    "    df.to_csv(path_csv, index=False, encoding='utf-8-sig')\n",
    "    df.to_parquet(path_parquet, index=False)\n",
    "    \n",
    "    logger.info(f\"üíæ Arquivos salvos:\")\n",
    "    logger.info(f\"   -> {path_csv}\")\n",
    "    logger.info(f\"   -> {path_parquet}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_result = fetch_ibrx100_from_b3_api()\n",
    "    \n",
    "    if df_result is not None and not df_result.empty:\n",
    "        print(\"\\n--- Amostra do IBRX-100 (API B3) ---\")\n",
    "        display(df_result.head())\n",
    "        save_data(df_result)\n",
    "    else:\n",
    "        logger.error(\"N√£o foi poss√≠vel gerar a lista de tickers.\")\n",
    "        \n",
    "    print(f\"\\nTempo total: {time.time() - start_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b492e",
   "metadata": {},
   "source": [
    "## üîó Mapeador Autom√°tico Ticker ‚Üî CNPJ (B3/CVM)\n",
    "\n",
    "Este utilit√°rio Python resolve o problema de desconex√£o de dados entre a **B3** (que opera via Tickers) e a **CVM** (que opera via CNPJ), criando um mapeamento confi√°vel e automatizado sem interven√ß√£o manual.\n",
    "\n",
    "## üéØ O Problema (O \"Elo Perdido\")\n",
    "Sistemas de an√°lise financeira (como o **Aurum**) frequentemente precisam cruzar dados de cota√ß√£o (B3) com dados fundamentalistas/cadastrais (CVM). No entanto:\n",
    "* A **B3** fornece o Ticker (ex: `ABEV3`) mas raramente fornece o CNPJ ou a Raz√£o Social completa na API p√∫blica.\n",
    "* A **CVM** fornece o CNPJ e a Raz√£o Social, mas n√£o sabe qual √© o Ticker associado.\n",
    "\n",
    "Este script cria uma \"ponte\" inteligente utilizando o **Yahoo Finance** para descobrir o nome comercial e algoritmos de **Fuzzy Matching** para vincul√°-lo ao CNPJ oficial.\n",
    "\n",
    "## üõ†Ô∏è Como Funciona (Pipeline L√≥gico)\n",
    "\n",
    "\n",
    "\n",
    "1.  **Extra√ß√£o B3:** O script consulta a API interna da B3 (`IndexProxy`) para obter a composi√ß√£o atualizada do √≠ndice **IBRX-100**.\n",
    "2.  **Dados Oficiais CVM:** Baixa automaticamente o arquivo `cad_cia_aberta.csv` diretamente do portal de Dados Abertos da CVM.\n",
    "3.  **Enriquecimento (A Ponte):** Para cada Ticker da B3, o script consulta o `yfinance` para descobrir o \"Nome Longo\" da empresa (ex: Converte `PETR4` ‚Üí \"Petr√≥leo Brasileiro S.A. - Petrobras\").\n",
    "4.  **Matching Probabil√≠stico:** Utiliza a biblioteca `rapidfuzz` para comparar o nome obtido no Yahoo com a Raz√£o Social da CVM. Se a similaridade for alta (Score > 70), o v√≠nculo √© criado.\n",
    "\n",
    "## üìã Pr√©-requisitos\n",
    "\n",
    "O script requer Python 3.8+ e as seguintes bibliotecas externas:\n",
    "\n",
    "pip install pandas requests yfinance rapidfuzz urllib3\n",
    "\n",
    "```mermaid \n",
    "graph TD\n",
    "    %% N√≥s de In√≠cio e Fim\n",
    "    Start([In√≠cio: main]) --> FetchB3\n",
    "    End([Fim: Salvar CSV e Estat√≠sticas])\n",
    "\n",
    "    %% ETAPA 1: Aquisi√ß√£o de Dados\n",
    "    subgraph \"1. Aquisi√ß√£o de Dados\"\n",
    "        FetchB3[üì° Fetch API B3: IBRX-100] --> CheckB3{Sucesso?}\n",
    "        CheckB3 -- N√£o --> Stop1([Encerrar])\n",
    "        CheckB3 -- Sim --> FetchCVM\n",
    "\n",
    "        FetchCVM[üèõÔ∏è Fetch Cadastro CVM Web] --> CheckCVM{Sucesso?}\n",
    "        CheckCVM -- N√£o --> Stop2([Encerrar])\n",
    "        CheckCVM -- Sim --> LoadLocal\n",
    "\n",
    "        %% CORRE√á√ÉO AQUI: Aspas adicionadas ao redor do texto\n",
    "        LoadLocal[\"üìÇ Load Local Fundamentals<br/>(fundamentals_wide.csv)\"] --> CheckLocal{Existe?}\n",
    "        \n",
    "        CheckLocal -- Sim --> DataReady[Dados Prontos]\n",
    "        CheckLocal -- N√£o --> DataReady\n",
    "    end\n",
    "\n",
    "    DataReady --> Enrich\n",
    "\n",
    "    %% ETAPA 2: Enriquecimento\n",
    "    subgraph \"2. Enriquecimento (Yahoo Finance)\"\n",
    "        Enrich[üîç Enrich Tickers with Names]\n",
    "        Enrich -->|Busca nome oficial da empresa| TickersEnriched[/DataFrame Enriquecido/]\n",
    "    end\n",
    "\n",
    "    TickersEnriched --> MatchLoop\n",
    "\n",
    "    %% ETAPA 3: L√≥gica de Matching (O Cora√ß√£o do Script)\n",
    "    subgraph \"3. Matching Otimizado (Itera√ß√£o por Ticker)\"\n",
    "        MatchLoop[üîÑ Loop: Para cada Ticker] --> SearchName{Tem Nome<br>do Yahoo?}\n",
    "        \n",
    "        SearchName -- N√£o --> UseTicker[Usar Ticker como Nome]\n",
    "        SearchName -- Sim --> CleanName[Limpar Sufixos S.A./PN/ON]\n",
    "        \n",
    "        UseTicker --> Step1\n",
    "        CleanName --> Step1\n",
    "\n",
    "        %% Prioridade 1: Local\n",
    "        Step1{1. Busca Local?} -->|Fuzzy Match em df_local| ScoreLocal{Score >= 70?}\n",
    "        \n",
    "        ScoreLocal -- Sim --> SetLocal[‚úÖ Definir CNPJ Local]\n",
    "        SetLocal --> SourceLocal[Source: local_fundamentals]\n",
    "        \n",
    "        ScoreLocal -- N√£o --> Step2\n",
    "\n",
    "        %% Prioridade 2: CVM Geral\n",
    "        Step2{2. Busca CVM?} -->|Fuzzy Match em df_cvm| ScoreCVM{Score CVM > Score Local?}\n",
    "        \n",
    "        ScoreCVM -- N√£o --> NoMatch[‚ùå Sem Match Confi√°vel]\n",
    "        NoMatch --> SourceNone[Source: none]\n",
    "\n",
    "        ScoreCVM -- Sim --> SetCVM[‚úÖ Definir CNPJ da CVM]\n",
    "        \n",
    "        %% CORRE√á√ÉO AQUI: Aspas adicionadas para seguran√ßa\n",
    "        SetCVM --> CheckCross{\"CNPJ existe<br>no Local?\"}\n",
    "        \n",
    "        CheckCross -- Sim --> SourceVer[Source: cvm_registry_verified]\n",
    "        CheckCross -- N√£o --> SourceNew[‚ö†Ô∏è Source: cvm_registry_new]\n",
    "\n",
    "        %% Sa√≠das do Loop\n",
    "        SourceLocal --> AppendRow\n",
    "        SourceNone --> AppendRow\n",
    "        SourceVer --> AppendRow\n",
    "        SourceNew --> AppendRow\n",
    "        \n",
    "        AppendRow[Adicionar √† Lista Final] --> NextTicker{Pr√≥ximo?}\n",
    "        NextTicker -- Sim --> MatchLoop\n",
    "    end\n",
    "\n",
    "    NextTicker -- N√£o --> End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import urllib3\n",
    "import io\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# --- Configura√ß√£o ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Diret√≥rios\n",
    "OUTPUT_DIR = Path(\"../data/dados_mapeamento\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FUNDAMENTALS_PATH = Path(\"../data/cvm/final/fundamentals_wide.csv\") \n",
    "\n",
    "URL_CVM_CADASTRO = \"https://dados.cvm.gov.br/dados/CIA_ABERTA/CAD/DADOS/cad_cia_aberta.csv\"\n",
    "\n",
    "def fetch_ibrx100_from_b3_api() -> pd.DataFrame:\n",
    "    \"\"\"Busca tickers do IBRX-100 direto da API da B3.\"\"\"\n",
    "    logger.info(\"üì° [B3] Iniciando requisi√ß√£o √† API...\")\n",
    "    \n",
    "    try:\n",
    "        params = {\"language\": \"pt-br\", \"pageNumber\": 1, \"pageSize\": 120, \"index\": \"IBXX\", \"segment\": \"1\"}\n",
    "        params_b64 = base64.b64encode(json.dumps(params).encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        url = f\"https://sistemaswebb3-listados.b3.com.br/indexProxy/indexCall/GetPortfolioDay/{params_b64}\"\n",
    "        \n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=15, verify=False)\n",
    "        \n",
    "        if response.status_code != 200: return None\n",
    "        \n",
    "        data = response.json()\n",
    "        results = data.get('results', [])\n",
    "        \n",
    "        if not results: return None\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        \n",
    "        coluna_ticker = next((col for col in ['codNeg', 'cod', 'acronym', 'asset'] if col in df.columns), None)\n",
    "        \n",
    "        if not coluna_ticker:\n",
    "            logger.error(\"‚ùå Coluna de ticker n√£o encontrada no JSON da B3.\")\n",
    "            return None\n",
    "            \n",
    "        df_final = df[[coluna_ticker]].rename(columns={coluna_ticker: 'ticker'})\n",
    "        df_final['ticker'] = df_final['ticker'].str.strip()\n",
    "        df_final['ticker_yahoo'] = df_final['ticker'] + \".SA\"\n",
    "        \n",
    "        logger.info(f\"‚úÖ [B3] {len(df_final)} ativos recuperados.\")\n",
    "        return df_final\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro B3: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_cvm_registry() -> pd.DataFrame:\n",
    "    \"\"\"Baixa e processa o cadastro oficial de CNPJs da CVM.\"\"\"\n",
    "    logger.info(\"üèõÔ∏è [CVM] Baixando cadastro oficial de companhias...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL_CVM_CADASTRO, timeout=30)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "            \n",
    "        csv_content = io.StringIO(response.content.decode('latin1')) \n",
    "        df_cvm = pd.read_csv(csv_content, sep=';', dtype=str)\n",
    "        \n",
    "        df_cvm = df_cvm[df_cvm['SIT'] == 'ATIVO']\n",
    "        \n",
    "        df_cvm = df_cvm[['CNPJ_CIA', 'DENOM_SOCIAL']].copy()\n",
    "        df_cvm['nome_limpo'] = df_cvm['DENOM_SOCIAL'].str.upper().str.strip()\n",
    "        \n",
    "        return df_cvm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro CVM: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_local_fundamentals() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega o arquivo local fundamentals_wide.csv para usar como \n",
    "    fonte priorit√°ria de 'Match'.\n",
    "    \"\"\"\n",
    "    logger.info(f\"üìÇ [Local] Carregando dados fundamentais de: {FUNDAMENTALS_PATH}\")\n",
    "    \n",
    "    if not FUNDAMENTALS_PATH.exists():\n",
    "        logger.warning(f\"‚ö†Ô∏è Arquivo local {FUNDAMENTALS_PATH} n√£o encontrado. Otimiza√ß√£o ser√° ignorada.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df_fund = pd.read_csv(\n",
    "            FUNDAMENTALS_PATH, \n",
    "            sep=';', \n",
    "            usecols=['CNPJ_CIA', 'DENOM_CIA'],\n",
    "            encoding='utf-8-sig' # Ou 'latin1' dependendo de como voc√™ salvou\n",
    "        )\n",
    "        \n",
    "        df_fund = df_fund.drop_duplicates(subset=['CNPJ_CIA']).copy()\n",
    "        df_fund['nome_limpo'] = df_fund['DENOM_CIA'].str.upper().str.strip()\n",
    "        \n",
    "        logger.info(f\"‚úÖ [Local] {len(df_fund)} empresas √∫nicas carregadas do hist√≥rico.\")\n",
    "        return df_fund\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro ao ler arquivo local: {e}\")\n",
    "        return None\n",
    "\n",
    "def enrich_tickers_with_names(df_b3: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Usa yfinance para descobrir o nome oficial da empresa por tr√°s do ticker.\"\"\"\n",
    "    logger.info(\"üîç [Enriquecimento] Buscando nomes das empresas via Yahoo Finance...\")\n",
    "    \n",
    "    names_map = {}\n",
    "    tickers_list = df_b3['ticker_yahoo'].tolist()\n",
    "    \n",
    "    total = len(tickers_list)\n",
    "    \n",
    "    tickers_obj = yf.Tickers(\" \".join(tickers_list))\n",
    "    \n",
    "    for i, ticker in enumerate(tickers_list):\n",
    "        try:\n",
    "            info = tickers_obj.tickers[ticker].info\n",
    "            name = info.get('longName') or info.get('shortName')\n",
    "            names_map[ticker] = name.upper() if name else None\n",
    "        except Exception:\n",
    "            names_map[ticker] = None\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            logger.info(f\"   Processado {i}/{total}...\")\n",
    "\n",
    "    df_b3['nome_yahoo'] = df_b3['ticker_yahoo'].map(names_map)\n",
    "    \n",
    "    clean_names = df_b3['nome_yahoo'].str.replace(r'\\s(PN|ON|UNIT|N1|N2|NM|S\\.A\\.|LTDA)$', '', regex=True)\n",
    "    df_b3['nome_busca'] = clean_names.fillna(df_b3['ticker']) # Fallback para o ticker se n√£o achar nome\n",
    "    \n",
    "    return df_b3\n",
    "\n",
    "def match_ticker_cnpj_optimized(df_b3: pd.DataFrame, df_cvm: pd.DataFrame, df_local: pd.DataFrame = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cruza tickers com CNPJs usando uma estrat√©gia em duas etapas:\n",
    "    1. Prioridade: Busca no arquivo local (fundamentals_wide).\n",
    "    2. Fallback: Busca no cadastro geral da CVM.\n",
    "    \"\"\"\n",
    "    logger.info(\"ü§ù [Matching] Cruzando bases com OTIMIZA√á√ÉO LOCAL...\")\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    local_names = []\n",
    "    local_lookup = {}\n",
    "    if df_local is not None:\n",
    "        local_names = df_local['nome_limpo'].tolist()\n",
    "        local_lookup = df_local.set_index('nome_limpo')['CNPJ_CIA'].to_dict()\n",
    "    \n",
    "    cvm_names = df_cvm['nome_limpo'].tolist()\n",
    "    cvm_lookup = df_cvm.set_index('nome_limpo')['CNPJ_CIA'].to_dict()\n",
    "    \n",
    "    for _, row in df_b3.iterrows():\n",
    "        ticker = row['ticker']\n",
    "        search_name = row['nome_busca']\n",
    "        \n",
    "        if not search_name:\n",
    "            matches.append({'ticker': ticker, 'CNPJ': None, 'match_score': 0, 'source': 'none'})\n",
    "            continue\n",
    "\n",
    "        best_name = None\n",
    "        score = 0\n",
    "        cnpj = None\n",
    "        source = 'none'\n",
    "\n",
    "        if local_names:\n",
    "            match_local = process.extractOne(search_name, local_names, scorer=fuzz.token_sort_ratio)\n",
    "            if match_local:\n",
    "                name_l, score_l, _ = match_local\n",
    "                if score_l >= 70: \n",
    "                    best_name = name_l\n",
    "                    score = score_l\n",
    "                    cnpj = local_lookup.get(best_name)\n",
    "                    source = 'local_fundamentals'\n",
    "        \n",
    "        if score < 70:\n",
    "            match_cvm = process.extractOne(search_name, cvm_names, scorer=fuzz.token_sort_ratio)\n",
    "            if match_cvm:\n",
    "                name_c, score_c, _ = match_cvm\n",
    "                \n",
    "                if score_c > score:\n",
    "                    best_name = name_c\n",
    "                    score = score_c\n",
    "                    cnpj = cvm_lookup.get(best_name)\n",
    "                    \n",
    "                    in_local = cnpj in local_lookup.values()\n",
    "                    source = 'cvm_registry_verified' if in_local else 'cvm_registry_new'\n",
    "\n",
    "        matches.append({\n",
    "            'ticker': ticker,\n",
    "            'nome_b3_yahoo': search_name,\n",
    "            'nome_oficial': best_name,\n",
    "            'CNPJ': cnpj,\n",
    "            'match_score': score,\n",
    "            'source': source \n",
    "        })\n",
    "            \n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_b3 = fetch_ibrx100_from_b3_api()\n",
    "    if df_b3 is None: return\n",
    "\n",
    "    df_cvm = fetch_cvm_registry()\n",
    "    if df_cvm is None: return\n",
    "\n",
    "    df_local = load_local_fundamentals()\n",
    "\n",
    "    df_b3_enriched = enrich_tickers_with_names(df_b3)\n",
    "\n",
    "    df_final = match_ticker_cnpj_optimized(df_b3_enriched, df_cvm, df_local)\n",
    "\n",
    "    final_path = OUTPUT_DIR / \"mapa_ticker_cnpj_otimizado.csv\"\n",
    "    df_final.to_csv(final_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\n--- Resultado Final (Amostra) ---\")\n",
    "    try:\n",
    "        display(df_final.head(15))\n",
    "    except NameError:\n",
    "        print(df_final.head(15).to_string())\n",
    "    \n",
    "    total = len(df_final)\n",
    "    encontrados = df_final['CNPJ'].notna().sum()\n",
    "    \n",
    "    from_local = len(df_final[df_final['source'] == 'local_fundamentals'])\n",
    "    from_cvm_ver = len(df_final[df_final['source'] == 'cvm_registry_verified'])\n",
    "    from_cvm_new = len(df_final[df_final['source'] == 'cvm_registry_new'])\n",
    "\n",
    "    print(f\"\\nüìä Estat√≠sticas de Mapeamento:\")\n",
    "    print(f\"   Total Tickers: {total}\")\n",
    "    print(f\"   Mapeados: {encontrados} ({(encontrados/total)*100:.1f}%)\")\n",
    "    print(f\"   --------------------------------\")\n",
    "    print(f\"   ‚úÖ Encontrado no Hist√≥rico Local: {from_local}\")\n",
    "    print(f\"   ‚úÖ Encontrado na CVM (J√° existe no local): {from_cvm_ver}\")\n",
    "    print(f\"   ‚ö†Ô∏è Encontrado na CVM (Novo/Sem dados locais): {from_cvm_new}\")\n",
    "    \n",
    "    print(f\"‚è±Ô∏è Tempo total: {time.time() - start_time:.2f} segundos\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
