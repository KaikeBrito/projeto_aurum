{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db719836",
   "metadata": {},
   "source": [
    "### **Documenta√ß√£o:** Calculadora de Quality Score (AurumQualityScoreCalculator)\n",
    "\n",
    "#### **1. Objetivo**\n",
    "\n",
    "Este script √© um dos pilares centrais do **Pilar 1 (Qualidade Financeira)** do projeto Aurum. Sua responsabilidade √© transformar os dados fundamentalistas brutos (extra√≠dos da CVM e formatados no `fundamentals_wide.parquet`) em m√©tricas de performance acion√°veis.\n",
    "\n",
    "O script executa um pipeline completo que:\n",
    "1.  Carrega os dados brutos da CVM.\n",
    "2.  Calcula os valores **TTM (Trailing Twelve Months / √öltimos 12 Meses)**, corrigindo a natureza \"Acumulada no Ano\" (YTD) dos dados da CVM.\n",
    "3.  Calcula um conjunto abrangente de **ratios financeiros** (Rentabilidade, Margens, Alavancagem, etc.) usando os dados TTM.\n",
    "4.  Calcula um **Aurum Quality Score** inicial, baseado em um *ranking percentile cross-sectional* (por data) desses ratios.\n",
    "5.  Salva os resultados hist√≥ricos e os mais recentes.\n",
    "\n",
    "#### **2. Configura√ß√£o (Input)**\n",
    "\n",
    "O script depende de um √∫nico arquivo de entrada, que deve ser gerado pelo pipeline de processamento da CVM:\n",
    "\n",
    "* **`ata/cvm/final/fundamentals_wide.parquet**: Um arquivo Parquet contendo os dados de Balan√ßo Patrimonial (BP) e Demonstra√ß√£o do Resultado (DRE) em formato \"wide\" (uma linha por empresa/data, m√∫ltiplas colunas de m√©tricas).\n",
    "    * **Importante:** O script assume que os dados da DRE (ex: `Receita L√≠quida`, `Lucro Bruto`) est√£o no formato **YTD (Acumulado no Ano)**, que √© o padr√£o da CVM.\n",
    "\n",
    "#### 3. Pipeline de Execu√ß√£o (Passo a Passo)\n",
    "\n",
    "A classe **AurumQualityScoreCalculator** gerencia todo o fluxo de trabalho:\n",
    "\n",
    "##### **Passo 1:** Carregar e Preparar Dados (`load_and_prepare_data`)\n",
    "\n",
    "* Carrega o arquivo `fundamentals_wide.parquet`.\n",
    "* Chama _clean_fundamentals_data para:\n",
    "    * Converter DT_FIM_EXERC para datetime.\n",
    "    * Remover quaisquer linhas duplicadas por CNPJ_CIA e DT_FIM_EXERC.\n",
    "    * **Ordenar** os dados por CNPJ_CIA e DT_FIM_EXERC, o que √© **essencial** para o c√°lculo de TTM.\n",
    "\n",
    "##### **Passo 2:** C√°lculo de TTM (`calculate_ttm_data`)\n",
    "\n",
    "Este √© o passo mais cr√≠tico do script. Ele converte os dados de fluxo (DRE) de YTD para TTM.\n",
    "\n",
    "* **L√≥gica:** O script agrupa por `CNPJ_CIA` e aplica a fun√ß√£o `rolling_sum_group`.\n",
    "* **Desacumula√ß√£o (YTD -> Trimestral):** Para cada coluna de DRE, ele calcula o valor trimestral fazendo:\n",
    "    quarterly = group[col] - group[col].shift(1).fillna(0)\n",
    "* **Anualiza√ß√£o (Trimestral -> TTM):** Em seguida, ele calcula a soma m√≥vel dos √∫ltimos 4 valores trimestrais:\n",
    "    group[f'{col}_ttm'] = quarterly.rolling(window=4, min_periods=4).sum()\n",
    "* O resultado √© salvo em self.ratios_df, pronto para o c√°lculo dos ratios.\n",
    "\n",
    "##### Passo 3: C√°lculo de Ratios Financeiros (`calculate_financial_ratios`)\n",
    "\n",
    "* Usando o self.ratios_df (que agora cont√©m as colunas `_ttm`), este m√©todo calcula os principais indicadores financeiros.\n",
    "* **Categorias:**\n",
    "    * **Contas de D√≠vida: D√≠vida Bruta, D√≠vida L√≠quida, Capital Investido**.\n",
    "    * **Rentabilidade (com TTM):** ROE, ROA, ROIC.\n",
    "    * **Margens (com TTM):** MARGEM_EBIT, MARGEM_LIQUIDA, MARGEM_BRUTA.\n",
    "    * **Alavancagem:** ALAVANCAGEM (Passivo/Ativo), DIVIDA_PL, DIVIDA_LIQ_EBIT.\n",
    "    * **Liquidez:** LIQUIDEZ_CORRENTE.\n",
    "    * **Efici√™ncia (com TTM):** GIRO_ATIVO.\n",
    "* Usa safe_divide para evitar erros de divis√£o por zero.\n",
    "\n",
    "##### Passo 3.1: Tratamento de Outliers (`_handle_ratio_outliers`)\n",
    "\n",
    "* Ap√≥s o c√°lculo, os ratios s√£o limpos.\n",
    "* Valores `infinitos` s√£o substitu√≠dos por `NaN`.\n",
    "* Os dados s√£o \"winsorizados\": valores extremos s√£o \"clipados\" (limitados) aos **percentis 1% (inferior) e 99% (superior)**. Isso torna o scoring subsequente mais robusto.\n",
    "\n",
    "##### Passo 4: C√°lculo do Score de Qualidade (`calculate_quality_scores`)\n",
    "\n",
    "Este m√©todo implementa a **Metodologia de Ranking Cross-Sectional**.\n",
    "\n",
    "* **Configura√ß√£o:** Define as m√©tricas, pesos e a dire√ß√£o (ex: `ROIC` -> maior √© melhor, `DIVIDA_LIQ_EBIT` -> menor √© melhor).\n",
    "* **Ranking por Data:** O script agrupa os dados por `DT_FIM_EXERC` (`grouped_by_date`).\n",
    "* Para cada m√©trica, ele calcula o **ranking percentile** de cada empresa *dentro daquele per√≠odo*:\n",
    "    `scores_df[score_col] = grouped_by_date[metric].rank(pct=True) * 100`\n",
    "* **Score Composto:** O `aurum_quality_score` √© calculado como a soma ponderada desses rankings (percentis de 0 a 100). Valores `NaN` s√£o preenchidos com a mediana (50) para n√£o penalizar empresas excessivamente.\n",
    "* **Classifica√ß√£o Final:** O script calcula `quality_quintile` e `quality_grade` (A-E) com base no ranking *final* do `aurum_quality_score` de cada per√≠odo.\n",
    "\n",
    "##### Passo 5 e 6: Salvar Resultados (`get_latest_scores` e `save_results`)\n",
    "\n",
    "* O script gera e salva quatro arquivos distintos no diret√≥rio `data/aurum_scores_output/`.\n",
    "\n",
    "#### 6. Sa√≠da (Output)\n",
    "\n",
    "A execu√ß√£o do script gera os seguintes arquivos em `data/aurum_scores_output/`:\n",
    "\n",
    "1.  **`aurum_quality_scores_complete.parquet`**:\n",
    "    * O arquivo mais importante. Cont√©m o **hist√≥rico completo** de todas as empresas, datas, ratios calculados e scores. Este ser√° o input para o `AurumScoringSystem` avan√ßado e para o *backtesting*.\n",
    "\n",
    "2.  **`aurum_quality_scores_latest.parquet`**:\n",
    "    * Um arquivo de conveni√™ncia que cont√©m apenas o **√∫ltimo registro (data mais recente)** de score/ratios para cada empresa.\n",
    "\n",
    "3.  **`aurum_quality_scores_latest.csv`**:\n",
    "    * Vers√£o CSV do arquivo acima, para f√°cil visualiza√ß√£o em planilhas.\n",
    "\n",
    "4.  **`aurum_scores_statistics.txt`**:\n",
    "    * Um relat√≥rio de texto (`.txt`) leg√≠vel, mostrando as estat√≠sticas do √∫ltimo per√≠odo (distribui√ß√£o de notas, Top 10 empresas) para uma verifica√ß√£o r√°pida.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 01:03:08,864 - INFO - üöÄ INICIANDO PIPELINE DO AURUM QUALITY SCORE (Vers√£o Final com ROIC Correto)\n",
      "2025-12-11 01:03:08,873 - INFO - üì• 1. CARREGANDO NOVO fundamentals_wide.parquet...\n",
      "2025-12-11 01:03:09,108 - INFO - ‚úÖ Dados carregados: (21559, 19)\n",
      "2025-12-11 01:03:09,113 - INFO - Colunas encontradas: ['CNPJ_CIA', 'DENOM_CIA', 'DT_FIM_EXERC', 'Custo dos Bens e/ou Servi√ßos Vendidos', 'EBIT', 'EBT', 'Lucro Bruto', 'Lucro L√≠quido Consolidado', 'Receita L√≠quida', 'Ativo Circulante', 'Ativo N√£o Circulante', 'Ativo Total', 'Caixa e Equivalentes', 'D√≠vida Curto Prazo', 'D√≠vida Longo Prazo', 'Passivo Circulante', 'Passivo N√£o Circulante', 'Passivo Total', 'Patrim√¥nio L√≠quido Consolidado']\n",
      "2025-12-11 01:03:09,131 - INFO - ‚úÖ Novas colunas (Caixa, D√≠vida CP, D√≠vida LP) encontradas!\n",
      "2025-12-11 01:03:09,274 - INFO - ‚è≥ 2. CALCULANDO TTM...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 729/729 [00:05<00:00, 123.56it/s]\n",
      "2025-12-11 01:03:15,197 - INFO - ‚úÖ TTM calculado.\n",
      "2025-12-11 01:03:15,200 - INFO - üßÆ 3. CALCULANDO RATIOS FINANCEIROS (COM TTM)...\n",
      "2025-12-11 01:03:15,214 - INFO - ‚úÖ D√≠vida Bruta, Capital Investido e D√≠vida L√≠quida calculados.\n",
      "2025-12-11 01:03:15,215 - INFO - üìà Calculando RENTABILIDADE...\n",
      "2025-12-11 01:03:15,233 - INFO - ‚úÖ ROIC (correto) calculado. M√©dia: 98.7966\n",
      "2025-12-11 01:03:15,243 - INFO - ‚öñÔ∏è Calculando ALAVANCAGEM...\n",
      "2025-12-11 01:03:15,252 - INFO - ‚úÖ Ratios de alavancagem (incluindo DIVIDA_PL, DIVIDA_LIQ_EBIT) calculados.\n",
      "2025-12-11 01:03:15,338 - INFO - üéØ RATIOS CALCULADOS e limpos.\n",
      "2025-12-11 01:03:15,340 - INFO - Colunas FINAIS de Ratios: ['CNPJ_CIA', 'DENOM_CIA', 'DT_FIM_EXERC', 'Custo dos Bens e/ou Servi√ßos Vendidos', 'EBIT', 'EBT', 'Lucro Bruto', 'Lucro L√≠quido Consolidado', 'Receita L√≠quida', 'Ativo Circulante', 'Ativo N√£o Circulante', 'Ativo Total', 'Caixa e Equivalentes', 'D√≠vida Curto Prazo', 'D√≠vida Longo Prazo', 'Passivo Circulante', 'Passivo N√£o Circulante', 'Passivo Total', 'Patrim√¥nio L√≠quido Consolidado', 'Receita L√≠quida_ttm', 'Custo dos Bens e/ou Servi√ßos Vendidos_ttm', 'Lucro Bruto_ttm', 'EBIT_ttm', 'EBT_ttm', 'Lucro L√≠quido Consolidado_ttm', 'D√≠vida Bruta', 'Capital Investido', 'D√≠vida L√≠quida', 'ROE', 'ROA', 'ROIC', 'MARGEM_EBIT', 'MARGEM_LIQUIDA', 'MARGEM_BRUTA', 'ALAVANCAGEM', 'DIVIDA_PL', 'DIVIDA_LIQ_EBIT', 'LIQUIDEZ_CORRENTE', 'GIRO_ATIVO']\n",
      "2025-12-11 01:03:15,342 - INFO - üéØ 4. CALCULANDO SCORES DE QUALIDADE...\n",
      "2025-12-11 01:03:15,359 - INFO - Configura√ß√£o de m√©tricas para score: {'ROIC': 0.25, 'ROE': 0.15, 'MARGEM_EBIT': 0.15, 'MARGEM_LIQUIDA': 0.1, 'DIVIDA_LIQ_EBIT': 0.15, 'LIQUIDEZ_CORRENTE': 0.1, 'GIRO_ATIVO': 0.1}\n",
      "2025-12-11 01:03:15,368 - INFO -   ‚úÖ Score ROIC calculado.\n",
      "2025-12-11 01:03:15,375 - INFO -   ‚úÖ Score ROE calculado.\n",
      "2025-12-11 01:03:15,386 - INFO -   ‚úÖ Score MARGEM_EBIT calculado.\n",
      "2025-12-11 01:03:15,396 - INFO -   ‚úÖ Score MARGEM_LIQUIDA calculado.\n",
      "2025-12-11 01:03:15,404 - INFO -   ‚úÖ Score DIVIDA_LIQ_EBIT calculado.\n",
      "2025-12-11 01:03:15,410 - INFO -   ‚úÖ Score LIQUIDEZ_CORRENTE calculado.\n",
      "2025-12-11 01:03:15,419 - INFO -   ‚úÖ Score GIRO_ATIVO calculado.\n",
      "2025-12-11 01:03:15,420 - INFO - ‚öñÔ∏è Calculando score composto...\n",
      "2025-12-11 01:03:15,429 - INFO - üèÜ Classificando empresas...\n",
      "2025-12-11 01:03:15,442 - INFO - Colunas FINAIS ANTES de salvar: ['CNPJ_CIA', 'DENOM_CIA', 'DT_FIM_EXERC', 'Custo dos Bens e/ou Servi√ßos Vendidos', 'EBIT', 'EBT', 'Lucro Bruto', 'Lucro L√≠quido Consolidado', 'Receita L√≠quida', 'Ativo Circulante', 'Ativo N√£o Circulante', 'Ativo Total', 'Caixa e Equivalentes', 'D√≠vida Curto Prazo', 'D√≠vida Longo Prazo', 'Passivo Circulante', 'Passivo N√£o Circulante', 'Passivo Total', 'Patrim√¥nio L√≠quido Consolidado', 'Receita L√≠quida_ttm', 'Custo dos Bens e/ou Servi√ßos Vendidos_ttm', 'Lucro Bruto_ttm', 'EBIT_ttm', 'EBT_ttm', 'Lucro L√≠quido Consolidado_ttm', 'D√≠vida Bruta', 'Capital Investido', 'D√≠vida L√≠quida', 'ROE', 'ROA', 'ROIC', 'MARGEM_EBIT', 'MARGEM_LIQUIDA', 'MARGEM_BRUTA', 'ALAVANCAGEM', 'DIVIDA_PL', 'DIVIDA_LIQ_EBIT', 'LIQUIDEZ_CORRENTE', 'GIRO_ATIVO', 'score_ROIC', 'score_ROE', 'score_MARGEM_EBIT', 'score_MARGEM_LIQUIDA', 'score_DIVIDA_LIQ_EBIT', 'score_LIQUIDEZ_CORRENTE', 'score_GIRO_ATIVO', 'aurum_quality_score', 'final_rank', 'quality_quintile', 'quality_grade']\n",
      "2025-12-11 01:03:15,445 - INFO - Salvando DataFrame com colunas: ['CNPJ_CIA', 'DENOM_CIA', 'DT_FIM_EXERC', 'Custo dos Bens e/ou Servi√ßos Vendidos', 'EBIT', 'EBT', 'Lucro Bruto', 'Lucro L√≠quido Consolidado', 'Receita L√≠quida', 'Ativo Circulante', 'Ativo N√£o Circulante', 'Ativo Total', 'Caixa e Equivalentes', 'D√≠vida Curto Prazo', 'D√≠vida Longo Prazo', 'Passivo Circulante', 'Passivo N√£o Circulante', 'Passivo Total', 'Patrim√¥nio L√≠quido Consolidado', 'Receita L√≠quida_ttm', 'Custo dos Bens e/ou Servi√ßos Vendidos_ttm', 'Lucro Bruto_ttm', 'EBIT_ttm', 'EBT_ttm', 'Lucro L√≠quido Consolidado_ttm', 'D√≠vida Bruta', 'Capital Investido', 'D√≠vida L√≠quida', 'ROE', 'ROA', 'ROIC', 'MARGEM_EBIT', 'MARGEM_LIQUIDA', 'MARGEM_BRUTA', 'ALAVANCAGEM', 'DIVIDA_PL', 'DIVIDA_LIQ_EBIT', 'LIQUIDEZ_CORRENTE', 'GIRO_ATIVO', 'score_ROIC', 'score_ROE', 'score_MARGEM_EBIT', 'score_MARGEM_LIQUIDA', 'score_DIVIDA_LIQ_EBIT', 'score_LIQUIDEZ_CORRENTE', 'score_GIRO_ATIVO', 'aurum_quality_score', 'final_rank', 'quality_quintile', 'quality_grade']\n",
      "2025-12-11 01:03:15,663 - INFO - üíæ Scores completos (hist√≥rico) salvos: data\\aurum_scores\\aurum_quality_scores_complete.parquet\n",
      "2025-12-11 01:03:15,774 - INFO - üíæ Scores mais recentes salvos: data\\aurum_scores\\aurum_quality_scores_latest.parquet e data\\aurum_scores\\aurum_quality_scores_latest.csv\n",
      "2025-12-11 01:03:15,789 - INFO - üíæ Estat√≠sticas salvas: data\\aurum_scores\\aurum_scores_statistics.txt\n",
      "2025-12-11 01:03:15,789 - INFO - üíæ Resultados (com ROIC correto) salvos em: {'complete_scores': WindowsPath('data/aurum_scores/aurum_quality_scores_complete.parquet'), 'latest_scores': WindowsPath('data/aurum_scores/aurum_quality_scores_latest.parquet'), 'statistics': WindowsPath('data/aurum_scores/aurum_scores_statistics.txt')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéâ AURUM QUALITY SCORE - RESULTADOS FINAIS (√öLTIMO PER√çODO)\n",
      "============================================================\n",
      "\n",
      "üìä TOTAL DE EMPRESAS: 729\n",
      "üìà SCORE M√âDIO: 49.27\n",
      "\n",
      "üìã DISTRIBUI√á√ÉO DAS NOTAS:\n",
      "   Nota A: 191 empresas\n",
      "   Nota B:  90 empresas\n",
      "   Nota C:  83 empresas\n",
      "   Nota D: 147 empresas\n",
      "   Nota E: 218 empresas\n",
      "\n",
      "ü•á TOP 10 EMPRESAS:\n",
      "    1. CAMIL ALIMENTOS S.A.                100.00 (Nota A)\n",
      "    2. MINUPAR PARTICIPACOES S.A.           90.07 (Nota A)\n",
      "    3. 521 PARTICIPACOES S.A. - EM LIQUIDA  89.17 (Nota A)\n",
      "    4. STEIN SP II PARTICIPA√á√ïES S.A.       87.37 (Nota A)\n",
      "    5. COMERCIAL QUINTELLA COM EXP SA EM L  84.67 (Nota A)\n",
      "    6. SONDOTECNICA ENGENHARIA SOLOS S.A.   83.36 (Nota A)\n",
      "    7. EPR INFRAESTRUTURA PR S.A.           83.19 (Nota A)\n",
      "    8. M√âLIUZ S.A.                          82.29 (Nota A)\n",
      "    9. RIVA INCORPORADORA S.A               79.77 (Nota A)\n",
      "   10. AURA ALMAS MINERA√á√ÉO S.A.            79.68 (Nota A)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "tqdm.pandas()\n",
    "\n",
    "class AurumQualityScoreCalculator:\n",
    "    \"\"\" Calcula TTM, ratios financeiros (incluindo ROIC correto) e scores \"\"\"\n",
    "\n",
    "    def __init__(self, fundamentals_path: str):\n",
    "        self.fundamentals_path = Path(fundamentals_path)\n",
    "        self.fundamentals_df = None\n",
    "        self.ratios_df = None\n",
    "        self.scores_df = None\n",
    "        self.dre_cols = [\n",
    "            'Receita L√≠quida', 'Custo dos Bens e/ou Servi√ßos Vendidos',\n",
    "            'Lucro Bruto', 'EBIT', 'EBT', 'Lucro L√≠quido Consolidado'\n",
    "        ]\n",
    "\n",
    "    def load_and_prepare_data(self) -> pd.DataFrame:\n",
    "        logger.info(\"üì• 1. CARREGANDO NOVO fundamentals_wide.parquet...\")\n",
    "        try:\n",
    "            self.fundamentals_df = pd.read_parquet(self.fundamentals_path)\n",
    "            logger.info(f\"‚úÖ Dados carregados: {self.fundamentals_df.shape}\")\n",
    "            logger.info(f\"Colunas encontradas: {self.fundamentals_df.columns.tolist()}\")\n",
    "            # Verificar se as novas colunas est√£o presentes\n",
    "            new_cols = ['Caixa e Equivalentes', 'D√≠vida Curto Prazo', 'D√≠vida Longo Prazo']\n",
    "            missing_new = [col for col in new_cols if col not in self.fundamentals_df.columns]\n",
    "            if missing_new:\n",
    "                 logger.error(f\"‚ùå ERRO: Novas colunas {missing_new} N√ÉO encontradas no input!\")\n",
    "                 raise ValueError(f\"Novas colunas faltando: {missing_new}\")\n",
    "            else:\n",
    "                 logger.info(\"‚úÖ Novas colunas (Caixa, D√≠vida CP, D√≠vida LP) encontradas!\")\n",
    "\n",
    "            self.fundamentals_df = self._clean_fundamentals_data(self.fundamentals_df)\n",
    "            return self.fundamentals_df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erro ao carregar dados: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _clean_fundamentals_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_clean = df.copy()\n",
    "        df_clean['DT_FIM_EXERC'] = pd.to_datetime(df_clean['DT_FIM_EXERC'], errors='coerce')\n",
    "        df_clean = df_clean.dropna(subset=['DT_FIM_EXERC'])\n",
    "        df_clean = df_clean.drop_duplicates(subset=['CNPJ_CIA', 'DT_FIM_EXERC'])\n",
    "        df_clean = df_clean.sort_values(['CNPJ_CIA', 'DT_FIM_EXERC'])\n",
    "        return df_clean\n",
    "\n",
    "    def calculate_ttm_data(self) -> pd.DataFrame:\n",
    "        if self.fundamentals_df is None: raise ValueError(\"Dados n√£o carregados.\")\n",
    "        logger.info(\"‚è≥ 2. CALCULANDO TTM...\")\n",
    "        df_ttm = self.fundamentals_df.copy()\n",
    "        def rolling_sum_group(group):\n",
    "            for col in self.dre_cols:\n",
    "                if col in group.columns:\n",
    "                    quarterly = group[col] - group[col].shift(1).fillna(0)\n",
    "                    group[f'{col}_ttm'] = quarterly.rolling(window=4, min_periods=4).sum()\n",
    "                else: group[f'{col}_ttm'] = np.nan\n",
    "            return group\n",
    "        grouped = df_ttm.groupby('CNPJ_CIA', group_keys=False)\n",
    "        self.ratios_df = grouped.progress_apply(rolling_sum_group)\n",
    "        logger.info(f\"‚úÖ TTM calculado.\")\n",
    "        return self.ratios_df\n",
    "\n",
    "    def calculate_financial_ratios(self) -> pd.DataFrame:\n",
    "        \"\"\" PASSO 3: Calcula ratios (com ROIC correto e ratios de d√≠vida) \"\"\"\n",
    "        if self.ratios_df is None: raise ValueError(\"Dados TTM n√£o calculados.\")\n",
    "        logger.info(\"üßÆ 3. CALCULANDO RATIOS FINANCEIROS (COM TTM)...\")\n",
    "        df = self.ratios_df.copy()\n",
    "\n",
    "        def get_col(df, col_name): return df.get(col_name, np.nan)\n",
    "        def safe_divide(num, den): return np.where(den == 0, np.nan, num / den)\n",
    "\n",
    "        # --- Contas de D√≠vida (USANDO AS NOVAS COLUNAS) ---\n",
    "        divida_cp = get_col(df, 'D√≠vida Curto Prazo').fillna(0) # Usando a coluna correta\n",
    "        divida_lp = get_col(df, 'D√≠vida Longo Prazo').fillna(0) # Usando a coluna correta\n",
    "        caixa = get_col(df, 'Caixa e Equivalentes').fillna(0)   # Usando a coluna correta\n",
    "        pl = get_col(df, 'Patrim√¥nio L√≠quido Consolidado').fillna(0)\n",
    "        \n",
    "        df['D√≠vida Bruta'] = divida_cp + divida_lp\n",
    "        df['Capital Investido'] = df['D√≠vida Bruta'] + pl # Defini√ß√£o correta\n",
    "        df['D√≠vida L√≠quida'] = df['D√≠vida Bruta'] - caixa # Defini√ß√£o correta\n",
    "        logger.info(\"‚úÖ D√≠vida Bruta, Capital Investido e D√≠vida L√≠quida calculados.\")\n",
    "\n",
    "        # --- RENTABILIDADE ---\n",
    "        logger.info(\"üìà Calculando RENTABILIDADE...\")\n",
    "        df['ROE'] = safe_divide(get_col(df, 'Lucro L√≠quido Consolidado_ttm'), pl)\n",
    "        df['ROA'] = safe_divide(get_col(df, 'Lucro L√≠quido Consolidado_ttm'), get_col(df, 'Ativo Total'))\n",
    "        # <<< ROIC CORRETO >>>\n",
    "        df['ROIC'] = safe_divide(get_col(df, 'EBIT_ttm'), df['Capital Investido'])\n",
    "        logger.info(f\"‚úÖ ROIC (correto) calculado. M√©dia: {df['ROIC'].mean():.4f}\")\n",
    "        # <<< FIM ROIC CORRETO >>>\n",
    "\n",
    "        # --- MARGENS ---\n",
    "        df['MARGEM_EBIT'] = safe_divide(get_col(df, 'EBIT_ttm'), get_col(df, 'Receita L√≠quida_ttm'))\n",
    "        df['MARGEM_LIQUIDA'] = safe_divide(get_col(df, 'Lucro L√≠quido Consolidado_ttm'), get_col(df, 'Receita L√≠quida_ttm'))\n",
    "        df['MARGEM_BRUTA'] = safe_divide(get_col(df, 'Lucro Bruto_ttm'), get_col(df, 'Receita L√≠quida_ttm'))\n",
    "\n",
    "        # --- ALAVANCAGEM ---\n",
    "        logger.info(\"‚öñÔ∏è Calculando ALAVANCAGEM...\")\n",
    "        df['ALAVANCAGEM'] = safe_divide(get_col(df, 'Passivo Total'), get_col(df, 'Ativo Total'))\n",
    "        df['DIVIDA_PL'] = safe_divide(df['D√≠vida Bruta'], pl) # Agora pode ser calculado\n",
    "        df['DIVIDA_LIQ_EBIT'] = safe_divide(df['D√≠vida L√≠quida'], get_col(df, 'EBIT_ttm')) # Agora pode ser calculado\n",
    "        logger.info(\"‚úÖ Ratios de alavancagem (incluindo DIVIDA_PL, DIVIDA_LIQ_EBIT) calculados.\")\n",
    "\n",
    "        # --- LIQUIDEZ ---\n",
    "        df['LIQUIDEZ_CORRENTE'] = safe_divide(get_col(df, 'Ativo Circulante'), get_col(df, 'Passivo Circulante'))\n",
    "\n",
    "        # --- EFICI√äNCIA ---\n",
    "        df['GIRO_ATIVO'] = safe_divide(get_col(df, 'Receita L√≠quida_ttm'), get_col(df, 'Ativo Total'))\n",
    "\n",
    "        self.ratios_df = self._handle_ratio_outliers(df)\n",
    "        logger.info(\"üéØ RATIOS CALCULADOS e limpos.\")\n",
    "        logger.info(f\"Colunas FINAIS de Ratios: {self.ratios_df.columns.tolist()}\")\n",
    "        return self.ratios_df\n",
    "\n",
    "    def _handle_ratio_outliers(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_clean = df.copy()\n",
    "        # Lista completa agora que temos os dados\n",
    "        ratio_columns = [\n",
    "            'ROE', 'ROA', 'ROIC', 'MARGEM_EBIT', 'MARGEM_LIQUIDA', 'MARGEM_BRUTA',\n",
    "            'ALAVANCAGEM', 'DIVIDA_PL', 'DIVIDA_LIQ_EBIT', 'LIQUIDEZ_CORRENTE', 'GIRO_ATIVO'\n",
    "        ]\n",
    "        for col in ratio_columns:\n",
    "            if col in df_clean.columns:\n",
    "                df_clean[col] = df_clean[col].replace([np.inf, -np.inf], np.nan)\n",
    "                if df_clean[col].notna().sum() > 0:\n",
    "                    lower = df_clean[col].quantile(0.01)\n",
    "                    upper = df_clean[col].quantile(0.99)\n",
    "                    df_clean[col] = df_clean[col].clip(lower=lower, upper=upper)\n",
    "        return df_clean\n",
    "\n",
    "    def calculate_quality_scores(self) -> pd.DataFrame:\n",
    "        \"\"\" PASSO 4: Calcula scores individuais e score composto \"\"\"\n",
    "        if self.ratios_df is None: raise ValueError(\"Ratios n√£o calculados.\")\n",
    "        logger.info(\"üéØ 4. CALCULANDO SCORES DE QUALIDADE...\")\n",
    "        scores_df = self.ratios_df.copy()\n",
    "        grouped_by_date = scores_df.groupby('DT_FIM_EXERC')\n",
    "\n",
    "        # Configura√ß√£o original (ou ajuste como preferir)\n",
    "        metrics_config = {\n",
    "            'ROIC': {'direction': 1, 'weight': 0.25}, # ROIC correto\n",
    "            'ROE': {'direction': 1, 'weight': 0.15},\n",
    "            'MARGEM_EBIT': {'direction': 1, 'weight': 0.15},\n",
    "            'MARGEM_LIQUIDA': {'direction': 1, 'weight': 0.10},\n",
    "            'DIVIDA_LIQ_EBIT': {'direction': -1, 'weight': 0.15}, # Agora existe\n",
    "            'LIQUIDEZ_CORRENTE': {'direction': 1, 'weight': 0.10},\n",
    "            'GIRO_ATIVO': {'direction': 1, 'weight': 0.10},\n",
    "            # 'ALAVANCAGEM': {'direction': -1, 'weight': 0.0}, # Pode remover ou ajustar peso\n",
    "        }\n",
    "        # Validar e ajustar pesos para somar 1.0\n",
    "        total_w = sum(c['weight'] for c in metrics_config.values())\n",
    "        if abs(total_w - 1.0) > 0.01:\n",
    "             logger.warning(f\"Soma dos pesos √© {total_w:.2f}. Ajustando proporcionalmente...\")\n",
    "             for k in metrics_config: metrics_config[k]['weight'] /= total_w\n",
    "\n",
    "        logger.info(f\"Configura√ß√£o de m√©tricas para score: { {k: v['weight'] for k, v in metrics_config.items()} }\")\n",
    "\n",
    "        for metric, config in metrics_config.items():\n",
    "            if metric in scores_df.columns and scores_df[metric].notna().any():\n",
    "                score_col = f'score_{metric}'\n",
    "                if config['direction'] == 1:\n",
    "                    scores_df[score_col] = grouped_by_date[metric].rank(pct=True) * 100\n",
    "                else:\n",
    "                    scores_df[score_col] = grouped_by_date[metric].rank(ascending=False, pct=True) * 100\n",
    "                logger.info(f\"  ‚úÖ Score {metric} calculado.\")\n",
    "            else:\n",
    "                 logger.warning(f\"M√©trica '{metric}' n√£o encontrada ou sem dados para score.\")\n",
    "\n",
    "        logger.info(\"‚öñÔ∏è Calculando score composto...\")\n",
    "        scores_df['aurum_quality_score'] = 0.0\n",
    "        total_applied_weight = 0.0\n",
    "        for metric, config in metrics_config.items():\n",
    "            score_col = f'score_{metric}'\n",
    "            if score_col in scores_df.columns:\n",
    "                scores_df['aurum_quality_score'] += scores_df[score_col].fillna(50) * config['weight']\n",
    "                total_applied_weight += config['weight']\n",
    "\n",
    "        if total_applied_weight > 0:\n",
    "            scores_df['aurum_quality_score'] /= total_applied_weight\n",
    "\n",
    "        # ... (c√≥digo de classifica√ß√£o e restante igual ao anterior) ...\n",
    "        logger.info(\"üèÜ Classificando empresas...\")\n",
    "        try:\n",
    "             valid_scores = scores_df['aurum_quality_score'].dropna()\n",
    "             if not valid_scores.empty:\n",
    "                  ranks = valid_scores.rank(ascending=False, pct=True)\n",
    "                  scores_df['final_rank'] = ranks\n",
    "                  try:\n",
    "                       scores_df['quality_quintile'] = pd.qcut(scores_df['final_rank'].dropna(), 5, labels=[f'{i}¬∫ Quintil' for i in range(1, 6)])\n",
    "                  except ValueError: scores_df['quality_quintile'] = pd.cut(scores_df['final_rank'].dropna(), 5, labels=False)\n",
    "                  scores_df['quality_grade'] = pd.cut(scores_df['final_rank'].dropna(), bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=['A', 'B', 'C', 'D', 'E'], right=True, include_lowest=True)\n",
    "             else: scores_df[['final_rank', 'quality_quintile', 'quality_grade']] = np.nan\n",
    "        except Exception as e:\n",
    "             logger.error(f\"Erro ao calcular ranks/grades: {e}\")\n",
    "             scores_df[['final_rank', 'quality_quintile', 'quality_grade']] = np.nan\n",
    "        \n",
    "        self.scores_df = scores_df\n",
    "        logger.info(f\"Colunas FINAIS ANTES de salvar: {self.scores_df.columns.tolist()}\")\n",
    "        return scores_df\n",
    "\n",
    "    # M√©todos get_latest_scores, save_results, _save_statistics s√£o iguais aos anteriores\n",
    "    # ... (Copie e cole os m√©todos get_latest_scores, save_results, _save_statistics da vers√£o anterior aqui) ...\n",
    "    def get_latest_scores(self) -> pd.DataFrame:\n",
    "        if self.scores_df is None: raise ValueError(\"Scores n√£o calculados.\")\n",
    "        latest_scores = self.scores_df.sort_values('DT_FIM_EXERC').groupby('CNPJ_CIA').last().reset_index()\n",
    "        return latest_scores\n",
    "\n",
    "    def save_results(self, output_dir: str = \"data/aurum_scores\"):\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        if self.scores_df is not None:\n",
    "            logger.info(f\"Salvando DataFrame com colunas: {self.scores_df.columns.tolist()}\")\n",
    "            if 'ROIC' not in self.scores_df.columns: logger.error(\"ERRO FATAL: Coluna 'ROIC' AUSENTE antes de salvar!\")\n",
    "            scores_path = output_path / \"aurum_quality_scores_complete.parquet\"\n",
    "            self.scores_df.to_parquet(scores_path, index=False)\n",
    "            logger.info(f\"üíæ Scores completos (hist√≥rico) salvos: {scores_path}\")\n",
    "        latest_scores = self.get_latest_scores()\n",
    "        latest_path = output_path / \"aurum_quality_scores_latest.parquet\"\n",
    "        latest_csv_path = output_path / \"aurum_quality_scores_latest.csv\"\n",
    "        latest_scores.to_parquet(latest_path, index=False)\n",
    "        latest_scores.to_csv(latest_csv_path, index=False, sep=';', encoding='utf-8-sig')\n",
    "        logger.info(f\"üíæ Scores mais recentes salvos: {latest_path} e {latest_csv_path}\")\n",
    "        stats_path = output_path / \"aurum_scores_statistics.txt\"\n",
    "        self._save_statistics(latest_scores, stats_path)\n",
    "        logger.info(f\"üíæ Estat√≠sticas salvas: {stats_path}\")\n",
    "        return {'complete_scores': scores_path,'latest_scores': latest_path,'statistics': stats_path}\n",
    "\n",
    "    def _save_statistics(self, scores_df: pd.DataFrame, stats_path: Path):\n",
    "        with open(stats_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"AURUM QUALITY SCORE - ESTAT√çSTICAS (√öLTIMO PER√çODO)\\n\" + \"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Total de empresas: {len(scores_df)}\\n\")\n",
    "            max_date = scores_df['DT_FIM_EXERC'].max()\n",
    "            f.write(f\"Per√≠odo mais recente: {max_date if pd.notna(max_date) else 'N/A'}\\n\\n\")\n",
    "            if 'aurum_quality_score' in scores_df.columns:\n",
    "                 f.write(\"DISTRIBUI√á√ÉO DOS SCORES:\\n\" + f\"  M√©dia: {scores_df['aurum_quality_score'].mean():.2f}\\n\" +\n",
    "                         f\"  Mediana: {scores_df['aurum_quality_score'].median():.2f}\\n\" + f\"  M√≠nimo: {scores_df['aurum_quality_score'].min():.2f}\\n\" +\n",
    "                         f\"  M√°ximo: {scores_df['aurum_quality_score'].max():.2f}\\n\\n\")\n",
    "            else: f.write(\"DISTRIBUI√á√ÉO DOS SCORES: N/A\\n\\n\")\n",
    "            if 'quality_grade' in scores_df.columns:\n",
    "                 f.write(\"DISTRIBUI√á√ÉO POR NOTAS:\\n\")\n",
    "                 grade_counts = scores_df['quality_grade'].value_counts().sort_index(ascending=True)\n",
    "                 for grade, count in grade_counts.items(): f.write(f\"  Nota {grade}: {count} empresas\\n\")\n",
    "            else: f.write(\"DISTRIBUI√á√ÉO POR NOTAS: N/A\\n\")\n",
    "            if 'aurum_quality_score' in scores_df.columns:\n",
    "                 f.write(\"\\nTOP 10 EMPRESAS:\\n\")\n",
    "                 top_10 = scores_df.nlargest(10, 'aurum_quality_score')[['DENOM_CIA', 'aurum_quality_score', 'quality_grade']]\n",
    "                 for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "                      grade = row.get('quality_grade', 'N/A')\n",
    "                      f.write(f\"  {i:2d}. {str(row['DENOM_CIA'])[:35]:35} {row['aurum_quality_score']:6.2f} (Nota {grade})\\n\")\n",
    "            else: f.write(\"\\nTOP 10 EMPRESAS: N/A\\n\")\n",
    "\n",
    "\n",
    "# ==================== EXECU√á√ÉO PRINCIPAL ====================\n",
    "def main():\n",
    "    logger.info(\"üöÄ INICIANDO PIPELINE DO AURUM QUALITY SCORE (Vers√£o Final com ROIC Correto)\")\n",
    "    try:\n",
    "        calculator = AurumQualityScoreCalculator(\n",
    "            fundamentals_path=\"../data/cvm/final/fundamentals_wide.parquet\" # Ler o NOVO input\n",
    "        )\n",
    "        calculator.load_and_prepare_data()\n",
    "        calculator.calculate_ttm_data()\n",
    "        calculator.calculate_financial_ratios() # Calcular ROIC correto e ratios de d√≠vida\n",
    "        calculator.calculate_quality_scores()   # Usar ROIC correto e ratios de d√≠vida\n",
    "        output_files = calculator.save_results(output_dir=\"../data/aurum_scores\") # Salvar no diret√≥rio correto\n",
    "        logger.info(f\"üíæ Resultados (com ROIC correto) salvos em: {output_files}\")\n",
    "\n",
    "        latest_scores = calculator.get_latest_scores()\n",
    "        # ... (impress√£o dos resultados igual) ...\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\nüéâ AURUM QUALITY SCORE - RESULTADOS FINAIS (√öLTIMO PER√çODO)\\n\" + \"=\"*60)\n",
    "        print(f\"\\nüìä TOTAL DE EMPRESAS: {len(latest_scores)}\")\n",
    "        if 'aurum_quality_score' in latest_scores.columns: print(f\"üìà SCORE M√âDIO: {latest_scores['aurum_quality_score'].mean():.2f}\")\n",
    "        print(f\"\\nüìã DISTRIBUI√á√ÉO DAS NOTAS:\")\n",
    "        if 'quality_grade' in latest_scores.columns:\n",
    "             grade_dist = latest_scores['quality_grade'].value_counts().sort_index(ascending=True)\n",
    "             for grade, count in grade_dist.items(): print(f\"   Nota {grade}: {count:3d} empresas\")\n",
    "        print(f\"\\nü•á TOP 10 EMPRESAS:\")\n",
    "        if 'aurum_quality_score' in latest_scores.columns:\n",
    "             top_10 = latest_scores.nlargest(10, 'aurum_quality_score')[['DENOM_CIA', 'aurum_quality_score', 'quality_grade']]\n",
    "             for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "                  grade = row.get('quality_grade', 'N/A')\n",
    "                  print(f\"   {i:2d}. {str(row['DENOM_CIA'])[:35]:35} {row['aurum_quality_score']:6.2f} (Nota {grade})\")\n",
    "\n",
    "        return calculator\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå ERRO NO PIPELINE: {e}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    aurum_calculator = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configura√ß√£o ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Arquivos de Input (VERIFICADOS) ---\n",
    "PATH_PRECOS_LIMPOS = \"data/historical/all_histories_cleaned.parquet\"\n",
    "PATH_PRECOS_WIDE = \"data/historical/prices_close_wide.parquet\"\n",
    "PATH_FUNDAMENTOS = \"data/aurum_scores/aurum_quality_scores_complete.parquet\" # Seu arquivo de fundamentos com ROIC\n",
    "PATH_SENTIMENTO = \"data/news/news_with_sentiment.parquet\"\n",
    "PATH_DE_PARA = \"data/ticker_cnpj_map.parquet\" # Seu arquivo de mapeamento\n",
    "\n",
    "# --- Arquivo de Output ---\n",
    "OUTPUT_DIR = \"data\"\n",
    "OUTPUT_FILENAME = \"aurum_master_features.parquet\"\n",
    "output_path = Path(OUTPUT_DIR) / OUTPUT_FILENAME\n",
    "\n",
    "def calcular_volatilidade_mensal():\n",
    "    # ... (c√≥digo igual, sem altera√ß√µes) ...\n",
    "    logger.info(\"Iniciando Unifica√ß√£o (Passo 1/3): C√°lculo da Volatilidade...\")\n",
    "    try: df_prices_daily = pd.read_parquet(PATH_PRECOS_LIMPOS)\n",
    "    except FileNotFoundError: logger.error(f\"Arquivo n√£o encontrado: {PATH_PRECOS_LIMPOS}\"); return None\n",
    "    df_prices_daily['date'] = pd.to_datetime(df_prices_daily['date'])\n",
    "    df_prices_daily['returns'] = df_prices_daily.groupby('ticker')['Adj Close'].pct_change()\n",
    "    df_prices_daily['VOLATILIDADE'] = df_prices_daily.groupby('ticker')['returns'].rolling(window=63, min_periods=30).std().reset_index(0, drop=True)\n",
    "    df_vol_mensal = df_prices_daily.set_index('date').groupby('ticker').resample('M').last()['VOLATILIDADE'].reset_index()\n",
    "    logger.info(f\"‚úÖ Volatilidade mensal calculada.\")\n",
    "    return df_vol_mensal\n",
    "\n",
    "def agregar_sentimento_mensal():\n",
    "    # ... (c√≥digo igual, sem altera√ß√µes) ...\n",
    "    logger.info(\"Iniciando Unifica√ß√£o (Passo 2/3): Agrega√ß√£o de Sentimento...\")\n",
    "    try: df_sent_raw = pd.read_parquet(PATH_SENTIMENTO)\n",
    "    except FileNotFoundError: logger.error(f\"Arquivo n√£o encontrado: {PATH_SENTIMENTO}\"); return None\n",
    "    df_sent_raw = df_sent_raw.rename(columns={'ticker_query': 'ticker', 'published_date': 'date'})\n",
    "    df_sent_raw['date'] = pd.to_datetime(df_sent_raw['date'], utc=True).dt.tz_localize(None)\n",
    "    if not df_sent_raw['ticker'].str.contains('.SA').any():\n",
    "        logger.warning(\"Tickers sem sufixo .SA. Adicionando...\")\n",
    "        df_sent_raw['ticker'] = df_sent_raw['ticker'].apply(lambda x: f\"{x}.SA\" if not str(x).endswith(\".SA\") else x)\n",
    "    df_sent_mensal = df_sent_raw.set_index('date').groupby('ticker').resample('M').agg(\n",
    "        SENTIMENT_MEDIO=('numeric_sentiment', 'mean'),\n",
    "        SENTIMENT_STD=('numeric_sentiment', 'std'),\n",
    "        NEWS_COUNT=('ticker', 'count')\n",
    "    ).reset_index()\n",
    "    logger.info(f\"‚úÖ Sentimento mensal agregado.\")\n",
    "    return df_sent_mensal\n",
    "\n",
    "def unificar_dataframe_mestre(df_vol_mensal, df_sent_mensal):\n",
    "    if df_vol_mensal is None or df_sent_mensal is None: return\n",
    "    logger.info(\"Iniciando Unifica√ß√£o (Passo 3/3): Jun√ß√£o do DataFrame Mestre...\")\n",
    "\n",
    "    # --- 1. Carregar Base de Pre√ßos Mensal ---\n",
    "    try:\n",
    "        df_close_wide = pd.read_parquet(PATH_PRECOS_WIDE)\n",
    "        df_base_mensal = df_close_wide.melt(ignore_index=False, var_name='ticker', value_name='Adj Close').reset_index()\n",
    "        df_base_mensal = df_base_mensal.rename(columns={'index': 'date'})\n",
    "        logger.info(f\"Base de pre√ßos (wide) carregada.\")\n",
    "    except FileNotFoundError: logger.error(f\"Arquivo n√£o encontrado: {PATH_PRECOS_WIDE}\"); return\n",
    "\n",
    "    # --- 2. Carregar Fundamentos (Trimestrais) ---\n",
    "    try:\n",
    "        df_fund = pd.read_parquet(PATH_FUNDAMENTOS)\n",
    "        df_fund = df_fund.rename(columns={'DT_FIM_EXERC': 'date'})\n",
    "        df_fund['date'] = pd.to_datetime(df_fund['date'])\n",
    "        logger.info(f\"Fundamentos carregados. Colunas: {df_fund.columns.tolist()}\")\n",
    "    except FileNotFoundError: logger.error(f\"Arquivo n√£o encontrado: {PATH_FUNDAMENTOS}\"); return\n",
    "    except KeyError as e: logger.error(f\"Erro ao renomear 'DT_FIM_EXERC': {e}\"); return\n",
    "\n",
    "    # --- 3. Carregar o Mapeamento (DE-PARA) ---\n",
    "    try:\n",
    "        df_mapping = pd.read_parquet(PATH_DE_PARA)\n",
    "        if 'ticker' not in df_mapping.columns or 'CNPJ_CIA' not in df_mapping.columns:\n",
    "             logger.error(f\"ERRO: Mapeamento {PATH_DE_PARA} sem 'ticker' ou 'CNPJ_CIA'.\")\n",
    "             return\n",
    "    except FileNotFoundError: logger.error(f\"Arquivo n√£o encontrado: {PATH_DE_PARA}\"); return\n",
    "\n",
    "    df_fund_com_ticker = pd.merge(df_fund, df_mapping, on='CNPJ_CIA', how='left')\n",
    "    df_fund_com_ticker = df_fund_com_ticker.dropna(subset=['ticker'])\n",
    "    logger.info(\"Fundamentos mapeados para tickers.\")\n",
    "\n",
    "    # --- 4. Construir o DataFrame Mestre ---\n",
    "    df_master = df_base_mensal.sort_values(by='date')\n",
    "    df_fund_com_ticker = df_fund_com_ticker.sort_values(by='date')\n",
    "\n",
    "    # 4a. Juntar Fundamentos (merge_asof)\n",
    "    df_master = pd.merge_asof(\n",
    "        df_master, df_fund_com_ticker, on='date', by='ticker', direction='backward'\n",
    "    )\n",
    "    logger.info(\"Merge 'as-of' dos fundamentos conclu√≠do.\")\n",
    "    logger.info(f\"Colunas no df_master AP√ìS merge_asof: {df_master.columns.tolist()}\") # DEBUG\n",
    "\n",
    "    # 4b. Juntar Volatilidade (merge)\n",
    "    df_master = pd.merge(df_master, df_vol_mensal, on=['date', 'ticker'], how='left')\n",
    "    logger.info(\"Merge da volatilidade conclu√≠do.\")\n",
    "\n",
    "    # 4c. Juntar Sentimento (merge)\n",
    "    df_master = pd.merge(df_master, df_sent_mensal, on=['date', 'ticker'], how='left')\n",
    "    logger.info(\"Merge do sentimento conclu√≠do.\")\n",
    "\n",
    "    # --- 5. Limpeza Final ---\n",
    "    df_master['SENTIMENT_MEDIO'] = df_master['SENTIMENT_MEDIO'].fillna(0)\n",
    "    df_master['VOLATILIDADE'] = df_master.groupby('ticker')['VOLATILIDADE'].ffill().bfill()\n",
    "\n",
    "    # <<< VERS√ÉO FINAL DO dropna >>>\n",
    "    # Usando ambas as colunas, pois df_master.info() provou que elas existem\n",
    "    fundamental_key_columns = ['ROE', 'ROIC'] # <--- USANDO AMBAS AS COLUNAS\n",
    "\n",
    "    missing_cols = [col for col in fundamental_key_columns if col not in df_master.columns]\n",
    "    if missing_cols:\n",
    "        # Este erro n√£o deve mais acontecer baseado no seu df.info()\n",
    "        logger.error(f\"ERRO CR√çTICO P√ìS-MERGE: Colunas {missing_cols} n√£o encontradas!\")\n",
    "        return\n",
    "    else:\n",
    "        logger.info(f\"Aplicando dropna nas colunas chave: {fundamental_key_columns}\")\n",
    "        df_master = df_master.dropna(subset=fundamental_key_columns)\n",
    "    # <<< FIM DA VERS√ÉO FINAL >>>\n",
    "\n",
    "    logger.info(f\"Limpeza final conclu√≠da. DataFrame Mestre pronto com {len(df_master)} linhas.\")\n",
    "\n",
    "    # --- 6. Salvar o Novo DataFrame Mestre ---\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    df_master.to_parquet(output_path, index=False)\n",
    "    logger.info(f\"‚úÖ‚úÖ‚úÖ DataFrame Mestre salvo em: {output_path} ‚úÖ‚úÖ‚úÖ\")\n",
    "\n",
    "    print(\"\\n--- Informa√ß√µes do DataFrame Mestre Gerado ---\")\n",
    "    df_master.info(verbose=True, show_counts=True) # Mostrar detalhes\n",
    "    print(\"\\n--- Amostra do DataFrame Mestre ---\")\n",
    "    sample_cols = ['date', 'ticker', 'ROE', 'ROIC', 'SENTIMENT_MEDIO', 'VOLATILIDADE']\n",
    "    print(df_master.sample(5)[[col for col in sample_cols if col in df_master.columns]])\n",
    "\n",
    "    return df_master\n",
    "\n",
    "# --- Execu√ß√£o Principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    df_vol = calcular_volatilidade_mensal()\n",
    "    df_sent = agregar_sentimento_mensal()\n",
    "    if df_vol is not None and df_sent is not None:\n",
    "        unificar_dataframe_mestre(df_vol, df_sent)\n",
    "    else:\n",
    "        logger.error(\"Falha ao gerar dados. O DataFrame Mestre n√£o foi criado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdfa04",
   "metadata": {},
   "source": [
    "### **Documenta√ß√£o:** Sistema de Scoring Avan√ßado (AurumScoringSystem)\n",
    "\n",
    "#### 1. Objetivo\n",
    "\n",
    "Este script √© o \"c√©rebro\" do projeto Aurum, onde a tese de investimento quantitativo √© de fato implementada. Ele representa a **evolu√ß√£o** do `AurumQualityScoreCalculator`, aplicando uma metodologia de scoring mais robusta e academicamente embasada.\n",
    "\n",
    "Enquanto o script anterior (`Calculator`) era focado em *calcular ratios* e criar um *score de ranking simples*, este script (`System`) tem como responsabilidades:\n",
    "1.  **Carregar uma Tese:** Define um conjunto expl√≠cito de **m√©tricas e pesos** baseados em teorias financeiras (ex: Fama & French, Graham & Dodd), armazenados na classe `ScoringMetric`.\n",
    "2.  **Normaliza√ß√£o Avan√ßada:** Substitui a normaliza√ß√£o por ranking (percentil) por uma **normaliza√ß√£o sigm√≥ide (baseada em Z-Score)**. Isso cria um score mais suave, robusto a outliers e que recompensa melhor empresas excepcionais.\n",
    "3.  **Incorporar Fatores M√∫ltiplos:** O sistema √© projetado para consumir *n√£o apenas* os ratios financeiros do script anterior, mas tamb√©m m√©tricas de **crescimento**, **sentimento (NLP)** e **volatilidade (pre√ßo)**.\n",
    "4.  **Validar-se:** Gera um relat√≥rio de valida√ß√£o que compara a contribui√ß√£o *te√≥rica* de cada m√©trica (o peso que definimos) com sua contribui√ß√£o *real* no score final.\n",
    "5.  **Gerar o Score Final:** Calcula o `aurum_quality_score` final e as classifica√ß√µes (A, B, C, D, E).\n",
    "\n",
    "#### 2. Configura√ß√£o (Input)\n",
    "\n",
    "Este script √© o **segundo passo** no pipeline de scoring e depende da sa√≠da do script anterior.\n",
    "\n",
    "1.  **Input Principal (Obrigat√≥rio):**\n",
    "    * `data/aurum_scores/aurum_quality_scores_complete.parquet`: Este √© o arquivo de **output** gerado pelo `AurumQualityScoreCalculator`. Ele cont√©m todos os ratios hist√≥ricos (ROE, ROIC, etc.) j√° calculados e tratados.\n",
    "\n",
    "2.  **Input Opcional (Configura√ß√£o):**\n",
    "    * O construtor `AurumScoringSystem(config_path=\"...\")` aceita um caminho para um arquivo `.json`. Isso permite carregar um conjunto personalizado de m√©tricas e pesos sem alterar o c√≥digo, facilitando a experimenta√ß√£o. Se nenhum caminho for fornecido, ele usa os pesos padr√£o definidos em `_initialize_scoring_metrics`.\n",
    "\n",
    "#### 3. Sa√≠da (Output)\n",
    "\n",
    "O script cria um novo diret√≥rio: `data/aurum_final_scores/`.\n",
    "\n",
    "1.  **`aurum_advanced_scores.parquet`**:\n",
    "    * O **hist√≥rico completo** de todas as empresas com os scores finais (0-100), notas (A-E) e quintis. Este √© o arquivo final que ser√° usado para o **backtesting**.\n",
    "\n",
    "2.  **`aurum_latest_advanced_scores.parquet`**:\n",
    "    * Um snapshot contendo apenas o **√∫ltimo score dispon√≠vel** para cada empresa.\n",
    "\n",
    "3.  **`aurum_scoring_config.json`**:\n",
    "    * Um arquivo `.json` que salva a tese exata (m√©tricas e pesos) usada nesta execu√ß√£o, garantindo a reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf380bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 00:28:10,561 - INFO - üöÄ INICIANDO SISTEMA AVAN√áADO DE SCORING AURUM\n",
      "2025-12-11 00:28:10,563 - INFO - ‚úÖ Sistema de scoring inicializado com 13 m√©tricas\n",
      "2025-12-11 00:28:10,566 - INFO - üìä Soma dos pesos: 1.000\n",
      "2025-12-11 00:28:10,568 - ERROR - ‚ùå Arquivo de ratios n√£o encontrado: data/aurum_master_features.parquet\n",
      "2025-12-11 00:28:10,568 - INFO - üí° Execute primeiro o c√°lculo dos ratios financeiros\n",
      "2025-12-11 00:28:10,570 - INFO - ‚úÖ Sistema de scoring inicializado com 13 m√©tricas\n",
      "2025-12-11 00:28:10,570 - INFO - üìä Soma dos pesos: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç AN√ÅLISE DE IMPORT√ÇNCIA DAS M√âTRICAS\n",
      "==================================================\n",
      "\n",
      "üìä RENTABILIDADE: 47.0%\n",
      "   ‚Ä¢ ROE                   18.0% - Return on Equity - Efici√™ncia do capital pr√≥prio\n",
      "   ‚Ä¢ ROA                   12.0% - Return on Assets - Efici√™ncia dos ativos\n",
      "   ‚Ä¢ MARGEM_EBIT            8.0% - Margem Operacional - Ebit/Receita\n",
      "   ‚Ä¢ MARGEM_LIQUIDA         5.0% - Margem L√≠quida - Lucro/Receita\n",
      "   ‚Ä¢ MARGEM_BRUTA           4.0% - Margem Bruta - Lucro Bruto/Receita\n",
      "\n",
      "üìä SOLV√äNCIA: 33.0%\n",
      "   ‚Ä¢ ALAVANCAGEM            9.0% - Alavancagem Total - Passivo/Ativo\n",
      "   ‚Ä¢ DIVIDA_PL              9.0% - D√≠vida/Patrim√¥nio L√≠quido\n",
      "   ‚Ä¢ LIQUIDEZ_CORRENTE      8.0% - Liquidez Corrente - Ativo Circulante/Passivo Circulante\n",
      "   ‚Ä¢ GIRO_ATIVO             7.0% - Giro do Ativo - Receita/Ativo Total\n",
      "\n",
      "üìä CRESCIMENTO: 10.0%\n",
      "   ‚Ä¢ CRESC_RECEITA          5.0% - Crescimento da Receita (anual)\n",
      "   ‚Ä¢ CRESC_LUCRO            5.0% - Crescimento do Lucro L√≠quido (anual)\n",
      "\n",
      "üìä EFICI√äNCIA: 10.0%\n",
      "   ‚Ä¢ SENTIMENT_MEDIO        5.0% - Sentimento M√©dio de Not√≠cias\n",
      "   ‚Ä¢ VOLATILIDADE           5.0% - Volatilidade dos Retornos (3 meses)\n",
      "\n",
      "üìà SOMA TOTAL: 100.0%\n",
      "\n",
      "üéØ PR√ìXIMOS PASSOS SUGERIDOS:\n",
      "   1. Analisar correla√ß√£o entre scores e performance futura\n",
      "   2. Ajustar pesos baseado em backtesting hist√≥rico\n",
      "   3. Implementar ajustes setoriais espec√≠ficos\n",
      "   4. Criar dashboard de monitoramento dos scores\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class ScoringMetric:\n",
    "    \"\"\"Classe para representar uma m√©trica de scoring\"\"\"\n",
    "    name: str\n",
    "    weight: float\n",
    "    direction: int  # 1 = maior √© melhor, -1 = menor √© melhor\n",
    "    description: str\n",
    "    min_value: float = None\n",
    "    max_value: float = None\n",
    "    ideal_range: Tuple[float, float] = None\n",
    "\n",
    "class AurumScoringSystem:\n",
    "    \"\"\"\n",
    "    Sistema avan√ßado de scoring para o Aurum Quality Score\n",
    "    com pesos baseados em fundamentos financeiros\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str = None):\n",
    "        self.scoring_metrics = self._initialize_scoring_metrics(config_path)\n",
    "        self.quality_thresholds = {\n",
    "            'A': 80,  # Excelente\n",
    "            'B': 60,  # Bom\n",
    "            'C': 40,  # Regular\n",
    "            'D': 20,  # Ruim\n",
    "            'E': 0    # Muito ruim\n",
    "        }\n",
    "        \n",
    "    def _initialize_scoring_metrics(self, config_path: str = None) -> Dict[str, ScoringMetric]:\n",
    "        \"\"\"\n",
    "        Inicializa as m√©tricas de scoring com pesos baseados em:\n",
    "        - Graham & Dodd: Security Analysis\n",
    "        - Fama & French: Three Factor Model  \n",
    "        - Pr√°ticas do mercado quantitativo\n",
    "        \"\"\"\n",
    "        \n",
    "        if config_path and Path(config_path).exists():\n",
    "            return self._load_custom_config(config_path)\n",
    "        \n",
    "        # Pesos baseados em import√¢ncia relativa para qualidade de empresas\n",
    "        # CORRE√á√ÉO: Soma total = 1.0 (100%)\n",
    "        metrics_config = {\n",
    "            # === RENTABILIDADE (47% do total) ===\n",
    "            'ROE': ScoringMetric(\n",
    "                name='ROE', weight=0.18, direction=1,  # Aumentado de 0.15 para 0.18\n",
    "                description='Return on Equity - Efici√™ncia do capital pr√≥prio',\n",
    "                ideal_range=(0.10, 0.25)\n",
    "            ),\n",
    "            'ROA': ScoringMetric(\n",
    "                name='ROA', weight=0.12, direction=1,\n",
    "                description='Return on Assets - Efici√™ncia dos ativos',\n",
    "                ideal_range=(0.05, 0.15)\n",
    "            ),\n",
    "            'MARGEM_EBIT': ScoringMetric(\n",
    "                name='MARGEM_EBIT', weight=0.08, direction=1,\n",
    "                description='Margem Operacional - Ebit/Receita',\n",
    "                ideal_range=(0.08, 0.20)\n",
    "            ),\n",
    "            'MARGEM_LIQUIDA': ScoringMetric(\n",
    "                name='MARGEM_LIQUIDA', weight=0.05, direction=1,  # Reduzido de 0.06 para 0.05\n",
    "                description='Margem L√≠quida - Lucro/Receita',\n",
    "                ideal_range=(0.06, 0.18)\n",
    "            ),\n",
    "            'MARGEM_BRUTA': ScoringMetric(\n",
    "                name='MARGEM_BRUTA', weight=0.04, direction=1,\n",
    "                description='Margem Bruta - Lucro Bruto/Receita',\n",
    "                ideal_range=(0.20, 0.50)\n",
    "            ),\n",
    "            \n",
    "            # === SOLV√äNCIA E ALAVANCAGEM (33% do total) ===\n",
    "            'ALAVANCAGEM': ScoringMetric(\n",
    "                name='ALAVANCAGEM', weight=0.09, direction=-1,  # Aumentado de 0.08 para 0.09\n",
    "                description='Alavancagem Total - Passivo/Ativo',\n",
    "                ideal_range=(0.30, 0.60)\n",
    "            ),\n",
    "            'DIVIDA_PL': ScoringMetric(\n",
    "                name='DIVIDA_PL', weight=0.09, direction=-1,  # Aumentado de 0.08 para 0.09\n",
    "                description='D√≠vida/Patrim√¥nio L√≠quido',\n",
    "                ideal_range=(0.50, 1.50)\n",
    "            ),\n",
    "            'LIQUIDEZ_CORRENTE': ScoringMetric(\n",
    "                name='LIQUIDEZ_CORRENTE', weight=0.08, direction=1,  # Aumentado de 0.07 para 0.08\n",
    "                description='Liquidez Corrente - Ativo Circulante/Passivo Circulante',\n",
    "                ideal_range=(1.20, 3.00)\n",
    "            ),\n",
    "            'GIRO_ATIVO': ScoringMetric(\n",
    "                name='GIRO_ATIVO', weight=0.07, direction=1,\n",
    "                description='Giro do Ativo - Receita/Ativo Total',\n",
    "                ideal_range=(0.30, 1.00)\n",
    "            ),\n",
    "            \n",
    "            # === CRESCIMENTO (10% do total) ===\n",
    "            'CRESC_RECEITA': ScoringMetric(\n",
    "                name='CRESC_RECEITA', weight=0.05, direction=1,\n",
    "                description='Crescimento da Receita (anual)',\n",
    "                ideal_range=(0.05, 0.30)\n",
    "            ),\n",
    "            'CRESC_LUCRO': ScoringMetric(\n",
    "                name='CRESC_LUCRO', weight=0.05, direction=1,\n",
    "                description='Crescimento do Lucro L√≠quido (anual)',\n",
    "                ideal_range=(0.08, 0.40)\n",
    "            ),\n",
    "            \n",
    "            # === EFICI√äNCIA (10% do total) ===\n",
    "            'SENTIMENT_MEDIO': ScoringMetric(\n",
    "                name='SENTIMENT_MEDIO', weight=0.05, direction=1,\n",
    "                description='Sentimento M√©dio de Not√≠cias',\n",
    "                ideal_range=(0.10, 0.80)\n",
    "            ),\n",
    "            'VOLATILIDADE': ScoringMetric(\n",
    "                name='VOLATILIDADE', weight=0.05, direction=-1,\n",
    "                description='Volatilidade dos Retornos (3 meses)',\n",
    "                ideal_range=(0.10, 0.40)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Validar que soma dos pesos = 1.0\n",
    "        total_weight = sum(metric.weight for metric in metrics_config.values())\n",
    "        if abs(total_weight - 1.0) > 0.001:\n",
    "            # Ajuste autom√°tico para garantir soma = 1.0\n",
    "            adjustment_factor = 1.0 / total_weight\n",
    "            for metric in metrics_config.values():\n",
    "                metric.weight *= adjustment_factor\n",
    "            \n",
    "            logger.info(f\"üîß Pesos ajustados automaticamente para soma = 1.0\")\n",
    "        \n",
    "        logger.info(f\"‚úÖ Sistema de scoring inicializado com {len(metrics_config)} m√©tricas\")\n",
    "        logger.info(f\"üìä Soma dos pesos: {sum(metric.weight for metric in metrics_config.values()):.3f}\")\n",
    "        \n",
    "        return metrics_config\n",
    "    \n",
    "    def _load_custom_config(self, config_path: str) -> Dict[str, ScoringMetric]:\n",
    "        \"\"\"Carrega configura√ß√£o personalizada de pesos\"\"\"\n",
    "        try:\n",
    "            with open(config_path, 'r', encoding='utf-8') as f:\n",
    "                config_data = json.load(f)\n",
    "            \n",
    "            metrics_config = {}\n",
    "            for metric_name, metric_data in config_data.items():\n",
    "                metrics_config[metric_name] = ScoringMetric(**metric_data)\n",
    "            \n",
    "            logger.info(f\"‚úÖ Configura√ß√£o personalizada carregada: {config_path}\")\n",
    "            return metrics_config\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Erro ao carregar configura√ß√£o: {e}\")\n",
    "            return self._initialize_scoring_metrics()  # Fallback para padr√£o\n",
    "    \n",
    "    def calculate_individual_scores(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calcula scores individuais para cada m√©trica usando normaliza√ß√£o avan√ßada\n",
    "        \"\"\"\n",
    "        scores_df = df.copy()\n",
    "        \n",
    "        logger.info(\"üéØ Calculando scores individuais...\")\n",
    "        \n",
    "        for metric_name, metric_config in self.scoring_metrics.items():\n",
    "            if metric_name not in scores_df.columns:\n",
    "                logger.warning(f\"‚ö†Ô∏è M√©trica {metric_name} n√£o encontrada no dataset\")\n",
    "                continue\n",
    "            \n",
    "            # CORRE√á√ÉO: Verifica√ß√£o de tipo de dados corrigida para NumPy 2.0\n",
    "            if scores_df[metric_name].dtype == object or pd.api.types.is_string_dtype(scores_df[metric_name]):\n",
    "                logger.warning(f\"‚ö†Ô∏è M√©trica {metric_name} √© do tipo texto - pulando\")\n",
    "                continue\n",
    "            \n",
    "            # Remover outliers extremos\n",
    "            clean_series = self._remove_outliers(scores_df[metric_name])\n",
    "            \n",
    "            if metric_config.direction == 1:\n",
    "                # MAIOR √© melhor - usar fun√ß√£o sigmoide para suavizar\n",
    "                scores_df[f'score_{metric_name}'] = self._sigmoid_normalization(clean_series)\n",
    "            else:\n",
    "                # MENOR √© melhor - inverter a normaliza√ß√£o\n",
    "                scores_df[f'score_{metric_name}'] = 1 - self._sigmoid_normalization(clean_series)\n",
    "            \n",
    "            # Aplicar pesos\n",
    "            scores_df[f'score_{metric_name}'] *= 100  # Converter para 0-100\n",
    "            scores_df[f'score_{metric_name}'] *= metric_config.weight\n",
    "            \n",
    "            valid_scores = scores_df[f'score_{metric_name}'].notna().sum()\n",
    "            logger.info(f\"  ‚úÖ {metric_name}: {valid_scores} scores calculados (peso: {metric_config.weight*100:.1f}%)\")\n",
    "        \n",
    "        return scores_df\n",
    "    \n",
    "    def _remove_outliers(self, series: pd.Series, n_std: int = 3) -> pd.Series:\n",
    "        \"\"\"Remove outliers usando m√©todo Z-score\"\"\"\n",
    "        # CORRE√á√ÉO: Verifica√ß√£o de tipo de dados atualizada para NumPy 2.0\n",
    "        if series.dtype == object or pd.api.types.is_string_dtype(series) or pd.api.types.is_categorical_dtype(series):\n",
    "            return series\n",
    "        \n",
    "        try:\n",
    "            z_scores = np.abs((series - series.mean()) / series.std())\n",
    "            clean_series = series.copy()\n",
    "            clean_series[z_scores > n_std] = np.nan\n",
    "            \n",
    "            outliers_removed = (z_scores > n_std).sum()\n",
    "            if outliers_removed > 0:\n",
    "                logger.debug(f\"  üéØ {outliers_removed} outliers removidos de {series.name}\")\n",
    "            \n",
    "            return clean_series\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"  ‚ö†Ô∏è Erro ao remover outliers de {series.name}: {e}\")\n",
    "            return series\n",
    "    \n",
    "    def _sigmoid_normalization(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Normaliza√ß√£o usando fun√ß√£o sigmoide para suavizar valores extremos\n",
    "        Mais robusta que rankeamento simples\n",
    "        \"\"\"\n",
    "        # CORRE√á√ÉO: Verifica√ß√£o de tipo de dados atualizada\n",
    "        if series.dtype == object or pd.api.types.is_string_dtype(series) or pd.api.types.is_categorical_dtype(series):\n",
    "            return series\n",
    "        \n",
    "        try:\n",
    "            # Standardizar para m√©dia 0, std 1\n",
    "            standardized = (series - series.mean()) / series.std()\n",
    "            \n",
    "            # Aplicar sigmoide\n",
    "            sigmoid = 1 / (1 + np.exp(-standardized))\n",
    "            \n",
    "            return sigmoid\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"  ‚ö†Ô∏è Erro na normaliza√ß√£o sigmoide de {series.name}: {e}\")\n",
    "            # Fallback: normaliza√ß√£o linear simples\n",
    "            return (series - series.min()) / (series.max() - series.min())\n",
    "    \n",
    "    def calculate_composite_score(self, scores_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calcula o score composto final com valida√ß√µes\n",
    "        \"\"\"\n",
    "        logger.info(\"‚öñÔ∏è Calculando score composto...\")\n",
    "        \n",
    "        # Identificar colunas de score\n",
    "        score_columns = [col for col in scores_df.columns if col.startswith('score_')]\n",
    "        \n",
    "        if not score_columns:\n",
    "            raise ValueError(\"‚ùå Nenhuma coluna de score encontrada\")\n",
    "        \n",
    "        logger.info(f\"üìã Colunas de score encontradas: {len(score_columns)}\")\n",
    "        \n",
    "        # Calcular score composto\n",
    "        scores_df['aurum_quality_score'] = scores_df[score_columns].sum(axis=1, skipna=True)\n",
    "        \n",
    "        # Normalizar para 0-100 (caso alguns pesos n√£o tenham sido aplicados)\n",
    "        max_possible_score = sum(metric.weight * 100 for metric in self.scoring_metrics.values())\n",
    "        scores_df['aurum_quality_score'] = (scores_df['aurum_quality_score'] / max_possible_score) * 100\n",
    "        \n",
    "        # Garantir que scores estejam entre 0 e 100\n",
    "        scores_df['aurum_quality_score'] = scores_df['aurum_quality_score'].clip(0, 100)\n",
    "        \n",
    "        # Aplicar classifica√ß√µes\n",
    "        scores_df = self._apply_quality_classifications(scores_df)\n",
    "        \n",
    "        valid_scores = scores_df['aurum_quality_score'].notna().sum()\n",
    "        logger.info(f\"‚úÖ Score composto calculado: {valid_scores} empresas\")\n",
    "        \n",
    "        return scores_df\n",
    "    \n",
    "    def _apply_quality_classifications(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Aplica classifica√ß√µes de qualidade (A, B, C, D, E)\"\"\"\n",
    "        \n",
    "        # Classifica√ß√£o por quintis\n",
    "        try:\n",
    "            df['quality_quintile'] = pd.qcut(\n",
    "                df['aurum_quality_score'], \n",
    "                5, \n",
    "                labels=['5¬∫ Quintil', '4¬∫ Quintil', '3¬∫ Quintil', '2¬∫ Quintil', '1¬∫ Quintil']\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Erro no qcut, usando cortes uniformes: {e}\")\n",
    "            # Fallback para cortes uniformes\n",
    "            df['quality_quintile'] = pd.cut(\n",
    "                df['aurum_quality_score'],\n",
    "                bins=5,\n",
    "                labels=['5¬∫ Quintil', '4¬∫ Quintil', '3¬∫ Quintil', '2¬∫ Quintil', '1¬∫ Quintil']\n",
    "            )\n",
    "        \n",
    "        # Classifica√ß√£o por letras baseada em thresholds\n",
    "        conditions = [\n",
    "            df['aurum_quality_score'] >= self.quality_thresholds['A'],\n",
    "            df['aurum_quality_score'] >= self.quality_thresholds['B'],\n",
    "            df['aurum_quality_score'] >= self.quality_thresholds['C'],\n",
    "            df['aurum_quality_score'] >= self.quality_thresholds['D'],\n",
    "            df['aurum_quality_score'] >= self.quality_thresholds['E']\n",
    "        ]\n",
    "        \n",
    "        choices = ['A', 'B', 'C', 'D', 'E']\n",
    "        \n",
    "        df['quality_grade'] = np.select(conditions, choices, default='E')\n",
    "        \n",
    "        # Classifica√ß√£o descritiva\n",
    "        grade_descriptions = {\n",
    "            'A': 'Excelente Qualidade',\n",
    "            'B': 'Boa Qualidade', \n",
    "            'C': 'Qualidade Regular',\n",
    "            'D': 'Qualidade Baixa',\n",
    "            'E': 'Qualidade Muito Baixa'\n",
    "        }\n",
    "        \n",
    "        df['quality_description'] = df['quality_grade'].map(grade_descriptions)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_sector_adjusted_scores(self, df: pd.DataFrame, sector_column: str = 'setor') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calcula scores ajustados por setor (quando informa√ß√£o de setor dispon√≠vel)\n",
    "        \"\"\"\n",
    "        if sector_column not in df.columns:\n",
    "            logger.warning(\"‚ö†Ô∏è Coluna de setor n√£o encontrada - pulando ajuste setorial\")\n",
    "            return df\n",
    "        \n",
    "        logger.info(\"üè≠ Aplicando ajuste setorial...\")\n",
    "        \n",
    "        df_sector_adjusted = df.copy()\n",
    "        \n",
    "        # Calcular medianas por setor para cada m√©trica\n",
    "        for metric_name in self.scoring_metrics.keys():\n",
    "            if metric_name in df.columns:\n",
    "                sector_medians = df.groupby(sector_column)[metric_name].median()\n",
    "                \n",
    "                # Ajustar scores baseado na mediana do setor\n",
    "                df_sector_adjusted[f'{metric_name}_sector_adj'] = df.apply(\n",
    "                    lambda row: row[metric_name] / sector_medians.get(row[sector_column], 1.0), \n",
    "                    axis=1\n",
    "                )\n",
    "        \n",
    "        # Recalcular scores com ajuste setorial\n",
    "        score_columns_adj = [col for col in df_sector_adjusted.columns if col.endswith('_sector_adj')]\n",
    "        \n",
    "        if score_columns_adj:\n",
    "            logger.info(f\"‚úÖ Ajuste setorial aplicado para {len(score_columns_adj)} m√©tricas\")\n",
    "        \n",
    "        return df_sector_adjusted\n",
    "    \n",
    "    def validate_scoring_system(self, scores_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida o sistema de scoring atrav√©s de an√°lises estat√≠sticas\n",
    "        \"\"\"\n",
    "        logger.info(\"üîç Validando sistema de scoring...\")\n",
    "        \n",
    "        validation_report = {\n",
    "            'basic_stats': {\n",
    "                'total_companies': len(scores_df),\n",
    "                'companies_with_scores': scores_df['aurum_quality_score'].notna().sum(),\n",
    "                'score_mean': scores_df['aurum_quality_score'].mean(),\n",
    "                'score_std': scores_df['aurum_quality_score'].std(),\n",
    "                'score_min': scores_df['aurum_quality_score'].min(),\n",
    "                'score_max': scores_df['aurum_quality_score'].max(),\n",
    "                'score_median': scores_df['aurum_quality_score'].median()\n",
    "            },\n",
    "            'distribution': {\n",
    "                'grade_A': len(scores_df[scores_df['quality_grade'] == 'A']),\n",
    "                'grade_B': len(scores_df[scores_df['quality_grade'] == 'B']),\n",
    "                'grade_C': len(scores_df[scores_df['quality_grade'] == 'C']),\n",
    "                'grade_D': len(scores_df[scores_df['quality_grade'] == 'D']),\n",
    "                'grade_E': len(scores_df[scores_df['quality_grade'] == 'E'])\n",
    "            },\n",
    "            'correlation_analysis': {},\n",
    "            'metric_contribution': {},\n",
    "            'weight_summary': {}\n",
    "        }\n",
    "        \n",
    "        # An√°lise de correla√ß√£o entre scores individuais e score final\n",
    "        score_columns = [col for col in scores_df.columns if col.startswith('score_')]\n",
    "        \n",
    "        for score_col in score_columns:\n",
    "            if score_col in scores_df.columns:\n",
    "                correlation = scores_df[score_col].corr(scores_df['aurum_quality_score'])\n",
    "                validation_report['correlation_analysis'][score_col] = round(correlation, 4) if not pd.isna(correlation) else None\n",
    "        \n",
    "        # Contribui√ß√£o de cada m√©trica\n",
    "        total_actual_weight = 0\n",
    "        for metric_name, metric_config in self.scoring_metrics.items():\n",
    "            score_col = f'score_{metric_name}'\n",
    "            if score_col in scores_df.columns:\n",
    "                actual_contribution = scores_df[score_col].mean() / scores_df['aurum_quality_score'].mean() * 100\n",
    "                if not pd.isna(actual_contribution):\n",
    "                    validation_report['metric_contribution'][metric_name] = {\n",
    "                        'weight': round(metric_config.weight * 100, 2),\n",
    "                        'actual_contribution': round(actual_contribution, 2),\n",
    "                        'description': metric_config.description\n",
    "                    }\n",
    "                    total_actual_weight += actual_contribution\n",
    "        \n",
    "        validation_report['weight_summary']['total_theoretical_weight'] = 100.0\n",
    "        validation_report['weight_summary']['total_actual_weight'] = round(total_actual_weight, 2)\n",
    "        \n",
    "        logger.info(\"‚úÖ Sistema de scoring validado\")\n",
    "        return validation_report\n",
    "    \n",
    "    def save_scoring_configuration(self, output_path: str = \"data/aurum_scoring_config.json\"):\n",
    "        \"\"\"Salva a configura√ß√£o do sistema de scoring\"\"\"\n",
    "        config_data = {}\n",
    "        \n",
    "        for metric_name, metric_config in self.scoring_metrics.items():\n",
    "            config_data[metric_name] = {\n",
    "                'name': metric_config.name,\n",
    "                'weight': metric_config.weight,\n",
    "                'direction': metric_config.direction,\n",
    "                'description': metric_config.description,\n",
    "                'min_value': metric_config.min_value,\n",
    "                'max_value': metric_config.max_value,\n",
    "                'ideal_range': metric_config.ideal_range\n",
    "            }\n",
    "        \n",
    "        output_dir = Path(output_path).parent\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        logger.info(f\"üíæ Configura√ß√£o salva em: {output_path}\")\n",
    "        return output_path\n",
    "\n",
    "# ==================== EXECU√á√ÉO PRINCIPAL ====================\n",
    "\n",
    "def run_advanced_scoring_system():\n",
    "    \"\"\"\n",
    "    Executa o sistema avan√ßado de scoring completo\n",
    "    \"\"\"\n",
    "    logger.info(\"üöÄ INICIANDO SISTEMA AVAN√áADO DE SCORING AURUM\")\n",
    "    \n",
    "    try:\n",
    "        # 1. INICIALIZAR SISTEMA DE SCORING\n",
    "        scoring_system = AurumScoringSystem()\n",
    "        \n",
    "        # 2. CARREGAR DADOS DO DATAFRAME MESTRE (Unificado)\n",
    "        ratios_path = \"data/aurum_master_features.parquet\" # <- ESTA √â A MUDAN√áA\n",
    "        \n",
    "        if not Path(ratios_path).exists():\n",
    "            logger.error(f\"‚ùå Arquivo de ratios n√£o encontrado: {ratios_path}\")\n",
    "            logger.info(\"üí° Execute primeiro o c√°lculo dos ratios financeiros\")\n",
    "            return None\n",
    "        \n",
    "        ratios_df = pd.read_parquet(ratios_path)\n",
    "        logger.info(f\"‚úÖ Dados de ratios carregados: {ratios_df.shape}\")\n",
    "        \n",
    "        # 3. CALCULAR SCORES INDIVIDUAIS\n",
    "        individual_scores_df = scoring_system.calculate_individual_scores(ratios_df)\n",
    "        \n",
    "        # 4. CALCULAR SCORE COMPOSTO\n",
    "        final_scores_df = scoring_system.calculate_composite_score(individual_scores_df)\n",
    "        \n",
    "        # 5. VALIDAR SISTEMA\n",
    "        validation_report = scoring_system.validate_scoring_system(final_scores_df)\n",
    "        \n",
    "        # 6. SALVAR RESULTADOS\n",
    "        output_dir = Path(\"data/aurum_final_scores\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Salvar scores finais\n",
    "        final_output_path = output_dir / \"aurum_advanced_scores.parquet\"\n",
    "        final_scores_df.to_parquet(final_output_path, index=False)\n",
    "        \n",
    "        # Salvar apenas os mais recentes\n",
    "        latest_scores = final_scores_df.sort_values(['CNPJ_CIA', 'DT_FIM_EXERC']).groupby('CNPJ_CIA').last().reset_index()\n",
    "        latest_output_path = output_dir / \"aurum_latest_advanced_scores.parquet\"\n",
    "        latest_scores.to_parquet(latest_output_path, index=False)\n",
    "        \n",
    "        # Salvar configura√ß√£o\n",
    "        config_path = scoring_system.save_scoring_configuration()\n",
    "        \n",
    "        # 7. RELAT√ìRIO FINAL\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üéâ SISTEMA DE SCORING AURUM - RESULTADOS FINAIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        basic_stats = validation_report['basic_stats']\n",
    "        distribution = validation_report['distribution']\n",
    "        \n",
    "        print(f\"\\nüìä ESTAT√çSTICAS GERAIS:\")\n",
    "        print(f\"   ‚Ä¢ Empresas no dataset: {basic_stats['total_companies']:,}\")\n",
    "        print(f\"   ‚Ä¢ Empresas com score:  {basic_stats['companies_with_scores']:,}\")\n",
    "        print(f\"   ‚Ä¢ Score m√©dio: {basic_stats['score_mean']:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Score mediano: {basic_stats['score_median']:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Melhor score: {basic_stats['score_max']:.2f}\")\n",
    "        print(f\"   ‚Ä¢ Pior score: {basic_stats['score_min']:.2f}\")\n",
    "        \n",
    "        print(f\"\\nüìà DISTRIBUI√á√ÉO DAS NOTAS:\")\n",
    "        print(f\"   ‚Ä¢ Nota A (Excelente): {distribution['grade_A']:3d} empresas\")\n",
    "        print(f\"   ‚Ä¢ Nota B (Boa):       {distribution['grade_B']:3d} empresas\") \n",
    "        print(f\"   ‚Ä¢ Nota C (Regular):   {distribution['grade_C']:3d} empresas\")\n",
    "        print(f\"   ‚Ä¢ Nota D (Baixa):     {distribution['grade_D']:3d} empresas\")\n",
    "        print(f\"   ‚Ä¢ Nota E (Muito Baixa): {distribution['grade_E']:3d} empresas\")\n",
    "        \n",
    "        print(f\"\\nü•á TOP 10 EMPRESAS POR QUALIDADE:\")\n",
    "        top_10 = latest_scores.nlargest(10, 'aurum_quality_score')[\n",
    "            ['DENOM_CIA', 'aurum_quality_score', 'quality_grade', 'quality_description']\n",
    "        ]\n",
    "        \n",
    "        for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "            print(f\"   {i:2d}. {row['DENOM_CIA'][:35]:35} {row['aurum_quality_score']:6.2f} ({row['quality_grade']})\")\n",
    "        \n",
    "        print(f\"\\nüìã CONTRIBUI√á√ÉO DAS M√âTRICAS:\")\n",
    "        metric_contrib = validation_report['metric_contribution']\n",
    "        for metric_name, contrib_info in list(metric_contrib.items())[:6]:  # Mostrar top 6\n",
    "            diff = contrib_info['actual_contribution'] - contrib_info['weight']\n",
    "            diff_symbol = \"+\" if diff > 0 else \"\"\n",
    "            print(f\"   ‚Ä¢ {metric_name:15}: {contrib_info['actual_contribution']:5.1f}% (peso: {contrib_info['weight']:.1f}%) {diff_symbol}{diff:+.1f}%\")\n",
    "        \n",
    "        weight_summary = validation_report['weight_summary']\n",
    "        print(f\"\\n‚öñÔ∏è  RESUMO DE PESOS:\")\n",
    "        print(f\"   ‚Ä¢ Peso te√≥rico total: {weight_summary['total_theoretical_weight']}%\")\n",
    "        print(f\"   ‚Ä¢ Peso real total:    {weight_summary['total_actual_weight']}%\")\n",
    "        \n",
    "        print(f\"\\nüíæ ARQUIVOS GERADOS:\")\n",
    "        print(f\"   ‚Ä¢ Scores completos: {final_output_path}\")\n",
    "        print(f\"   ‚Ä¢ Scores recentes:  {latest_output_path}\")\n",
    "        print(f\"   ‚Ä¢ Configura√ß√£o:     {config_path}\")\n",
    "        \n",
    "        return {\n",
    "            'scoring_system': scoring_system,\n",
    "            'final_scores': final_scores_df,\n",
    "            'latest_scores': latest_scores,\n",
    "            'validation_report': validation_report\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Erro no sistema de scoring: {e}\")\n",
    "        import traceback\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n",
    "\n",
    "# Fun√ß√£o para an√°lise r√°pida de m√©tricas\n",
    "def analyze_metric_importance():\n",
    "    \"\"\"Analisa a import√¢ncia de cada m√©trica no sistema de scoring\"\"\"\n",
    "    scoring_system = AurumScoringSystem()\n",
    "    \n",
    "    print(\"\\nüîç AN√ÅLISE DE IMPORT√ÇNCIA DAS M√âTRICAS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    metrics_by_category = {\n",
    "        'RENTABILIDADE': ['ROE', 'ROA', 'MARGEM_EBIT', 'MARGEM_LIQUIDA', 'MARGEM_BRUTA'],\n",
    "        'SOLV√äNCIA': ['ALAVANCAGEM', 'DIVIDA_PL', 'LIQUIDEZ_CORRENTE', 'GIRO_ATIVO'],\n",
    "        'CRESCIMENTO': ['CRESC_RECEITA', 'CRESC_LUCRO'],\n",
    "        'EFICI√äNCIA': ['SENTIMENT_MEDIO', 'VOLATILIDADE']\n",
    "    }\n",
    "    \n",
    "    total_weight = 0\n",
    "    for category, metrics in metrics_by_category.items():\n",
    "        category_weight = sum(\n",
    "            scoring_system.scoring_metrics[metric].weight \n",
    "            for metric in metrics \n",
    "            if metric in scoring_system.scoring_metrics\n",
    "        )\n",
    "        total_weight += category_weight\n",
    "        \n",
    "        print(f\"\\nüìä {category}: {category_weight*100:.1f}%\")\n",
    "        for metric in metrics:\n",
    "            if metric in scoring_system.scoring_metrics:\n",
    "                metric_config = scoring_system.scoring_metrics[metric]\n",
    "                print(f\"   ‚Ä¢ {metric:20} {metric_config.weight*100:5.1f}% - {metric_config.description}\")\n",
    "    \n",
    "    print(f\"\\nüìà SOMA TOTAL: {total_weight*100:.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar sistema completo\n",
    "    results = run_advanced_scoring_system()\n",
    "    \n",
    "    # Mostrar an√°lise de import√¢ncia\n",
    "    analyze_metric_importance()\n",
    "    \n",
    "    print(\"\\nüéØ PR√ìXIMOS PASSOS SUGERIDOS:\")\n",
    "    print(\"   1. Analisar correla√ß√£o entre scores e performance futura\")\n",
    "    print(\"   2. Ajustar pesos baseado em backtesting hist√≥rico\") \n",
    "    print(\"   3. Implementar ajustes setoriais espec√≠ficos\")\n",
    "    print(\"   4. Criar dashboard de monitoramento dos scores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
