{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f0869d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_analysis_pipeline_final.py\n",
    "\"\"\"\n",
    "Pipeline robusto de análise de sentimento (batch), com fallback lexicon.\n",
    "Salva parquet + csv e gera agregação por ticker/mês.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "from typing import List, Tuple, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers (carregado de forma condicional)\n",
    "try:\n",
    "    from transformers import pipeline, AutoModelForSequenceClassification\n",
    "except Exception:\n",
    "    pipeline = None\n",
    "    AutoModelForSequenceClassification = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3290da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações de arquivo ---\n",
    "NEWS_DIR = os.path.join(\"..\", \"data\", \"news\")\n",
    "INPUT_FILE = os.path.join(NEWS_DIR, \"raw_news_data.parquet\")\n",
    "OUTPUT_FILE_PARQUET = os.path.join(NEWS_DIR, \"news_with_sentiment.parquet\")\n",
    "OUTPUT_FILE_CSV = os.path.join(NEWS_DIR, \"news_with_sentiment.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aedcaa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Modelos candidatos (ordem de preferência) ---\n",
    "MODEL_CANDIDATES = [\n",
    "    \"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "    \"lipaoMai/BERT-sentiment-analysis-portuguese-with-undersampling-v2\",\n",
    "    \"pysentimiento/bertweet-pt-sentiment\",\n",
    "    \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ddac428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parâmetros de inferência ---\n",
    "BATCH_SIZE = 64       # ajuste conforme memória (CPU/GPU)\n",
    "MAX_CHARS = 2000      # truncar textos muito longos por caracteres (você pode melhorar com tokenizer)\n",
    "TRUNCATE_TOKENS = 512 # caso use tokenizer: limite de tokens (não aplicado aqui diretamente)\n",
    "\n",
    "POS_WORDS = {\"bom\",\"ótimo\",\"excelente\",\"positivo\",\"cresceu\",\"alta\",\"superior\",\"melhor\",\"lucro\",\"recupera\"}\n",
    "NEG_WORDS = {\"ruim\",\"queda\",\"prejuízo\",\"redução\",\"negativo\",\"menor\",\"rebaixamento\",\"perda\",\"crise\",\"dívida\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2410680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- utilitários ----------------\n",
    "def torch_available() -> bool:\n",
    "    try:\n",
    "        import torch\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a9e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_device() -> int:\n",
    "    \"\"\"Retorna 0 para GPU (se existir) ou -1 para CPU.\"\"\"\n",
    "    if torch_available():\n",
    "        import torch\n",
    "        return 0 if torch.cuda.is_available() else -1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8750a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_lexicon_sentiment(text: str) -> Tuple[Optional[str], float]:\n",
    "    \"\"\"Fallback muito simples baseado em presença de palavras (não substitui modelo ML).\"\"\"\n",
    "    t = str(text).lower()\n",
    "    pos = sum(1 for w in POS_WORDS if w in t)\n",
    "    neg = sum(1 for w in NEG_WORDS if w in t)\n",
    "    if pos > neg:\n",
    "        score = pos/(pos+neg+1e-9)\n",
    "        return \"positive\", float(score)\n",
    "    if neg > pos:\n",
    "        score = neg/(pos+neg+1e-9)\n",
    "        return \"negative\", float(score)\n",
    "    return \"neutral\", 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e241c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_load_pipeline(models: List[str], task: str = \"sentiment-analysis\", device: int = -1, use_auth_token: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Tenta carregar modelos em ordem. Retorna (pipeline, model_name, label_map).\n",
    "    Só passa use_auth_token para pipeline se for uma string não-vazia.\n",
    "    \"\"\"\n",
    "    if pipeline is None:\n",
    "        print(\"transformers.pipeline não está disponível (biblioteca não instalada).\")\n",
    "        return None, None, None\n",
    "\n",
    "    last_exc = None\n",
    "    for m in models:\n",
    "        try:\n",
    "            print(f\"Tentando carregar modelo '{m}' (device={device}) ...\")\n",
    "            # construir kwargs dinamicamente: só incluir token se houver\n",
    "            kwargs = {}\n",
    "            if use_auth_token:\n",
    "                kwargs['use_auth_token'] = use_auth_token\n",
    "            # device já definido\n",
    "            kwargs['device'] = device\n",
    "\n",
    "            pipe = pipeline(task, model=m, **kwargs)\n",
    "\n",
    "            # label_map: tenta inferir id2label se possível (mas só quando torch disponível)\n",
    "            label_map = {}\n",
    "            try:\n",
    "                if AutoModelForSequenceClassification is not None and torch_available():\n",
    "                    model_inst = AutoModelForSequenceClassification.from_pretrained(m, use_auth_token=use_auth_token if use_auth_token else None)\n",
    "                    id2label = getattr(model_inst.config, \"id2label\", None)\n",
    "                    if id2label:\n",
    "                        for k, v in id2label.items():\n",
    "                            lv = str(v).lower()\n",
    "                            if \"neg\" in lv: label_map[k] = \"negative\"\n",
    "                            elif \"pos\" in lv: label_map[k] = \"positive\"\n",
    "                            elif \"neu\" in lv or \"neutral\" in lv: label_map[k] = \"neutral\"\n",
    "                # heurísticas para alguns modelos conhecidos\n",
    "                if not label_map:\n",
    "                    if \"cardiffnlp/twitter-xlm-roberta\" in m:\n",
    "                        label_map = {\"LABEL_0\":\"negative\",\"LABEL_1\":\"neutral\",\"LABEL_2\":\"positive\"}\n",
    "                    elif \"pysentimiento/bertweet\" in m or \"pysentimiento\" in m:\n",
    "                        label_map = {\"POS\":\"positive\",\"NEG\":\"negative\",\"NEU\":\"neutral\"}\n",
    "                    elif \"nlptown\" in m:\n",
    "                        label_map = {\"1 star\":\"negative\",\"2 star\":\"negative\",\"3 star\":\"neutral\",\"4 star\":\"positive\",\"5 star\":\"positive\"}\n",
    "            except Exception:\n",
    "                label_map = {}\n",
    "\n",
    "            print(f\"Modelo '{m}' carregado com sucesso.\")\n",
    "            return pipe, m, label_map\n",
    "\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            print(f\"Falha ao carregar '{m}': {repr(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Nenhum modelo pôde ser carregado. Último erro:\", repr(last_exc))\n",
    "    return None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "709dfcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(label: Optional[str], label_map: dict) -> Optional[str]:\n",
    "    \"\"\"Normaliza label usando label_map ou heurísticas simples.\"\"\"\n",
    "    if label is None:\n",
    "        return None\n",
    "    # se map existir e label in it\n",
    "    if label_map and label in label_map:\n",
    "        return label_map[label]\n",
    "    l = str(label).lower()\n",
    "    if \"pos\" in l or \"positive\" in l or \"5\" in l or \"4\" in l:\n",
    "        return \"positive\"\n",
    "    if \"neg\" in l or \"negative\" in l or \"1\" in l or \"2\" in l:\n",
    "        return \"negative\"\n",
    "    if \"neu\" in l or \"neutral\" in l:\n",
    "        return \"neutral\"\n",
    "    # fallback: retorna label original\n",
    "    return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17aebe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sentiment_inference(pipe, texts: List[str], batch_size:int = 32, label_map: dict = None):\n",
    "    \"\"\"Roda pipeline em batches e retorna lista de tuples (norm_label, score).\"\"\"\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        batch_clean = [\"\" if (x is None or (isinstance(x, float) and math.isnan(x))) else str(x) for x in batch]\n",
    "        # truncar por caracteres (simples) para reduzir OOM com inputs gigantes\n",
    "        batch_clean = [t if len(t) <= MAX_CHARS else t[:MAX_CHARS] for t in batch_clean]\n",
    "        try:\n",
    "            outs = pipe(batch_clean)\n",
    "        except Exception as e:\n",
    "            # se falhar por causa do batch_size, reduz e tenta recursivamente\n",
    "            if batch_size > 1:\n",
    "                return batch_sentiment_inference(pipe, texts, batch_size=max(1, batch_size//2), label_map=label_map)\n",
    "            else:\n",
    "                raise\n",
    "        for o in outs:\n",
    "            label = o.get(\"label\") if isinstance(o, dict) else None\n",
    "            score = float(o.get(\"score\", 0.0)) if isinstance(o, dict) else None\n",
    "            norm = normalize_label(label, label_map)\n",
    "            results.append((norm, score))\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08964fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_numeric(label: Optional[str]) -> int:\n",
    "    if label is None:\n",
    "        return 0\n",
    "    l = str(label).lower()\n",
    "    if \"pos\" in l or \"positive\" in l:\n",
    "        return 1\n",
    "    if \"neg\" in l or \"negative\" in l:\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b99fc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando pipeline de sentimento.\n",
      "Loaded input: (2766, 6)\n",
      "Device selecionado: -1 (0 => gpu, -1 => cpu)\n",
      "Tentando carregar modelo 'cardiffnlp/twitter-xlm-roberta-base-sentiment' (device=-1) ...\n",
      "Falha ao carregar 'cardiffnlp/twitter-xlm-roberta-base-sentiment': NameError(\"name 'torch' is not defined\")\n",
      "Tentando carregar modelo 'lipaoMai/BERT-sentiment-analysis-portuguese-with-undersampling-v2' (device=-1) ...\n",
      "Falha ao carregar 'lipaoMai/BERT-sentiment-analysis-portuguese-with-undersampling-v2': NameError(\"name 'torch' is not defined\")\n",
      "Tentando carregar modelo 'pysentimiento/bertweet-pt-sentiment' (device=-1) ...\n",
      "Falha ao carregar 'pysentimiento/bertweet-pt-sentiment': NameError(\"name 'torch' is not defined\")\n",
      "Tentando carregar modelo 'nlptown/bert-base-multilingual-uncased-sentiment' (device=-1) ...\n",
      "Falha ao carregar 'nlptown/bert-base-multilingual-uncased-sentiment': NameError(\"name 'torch' is not defined\")\n",
      "Tentando carregar modelo 'distilbert-base-uncased-finetuned-sst-2-english' (device=-1) ...\n",
      "Falha ao carregar 'distilbert-base-uncased-finetuned-sst-2-english': NameError(\"name 'torch' is not defined\")\n",
      "Nenhum modelo pôde ser carregado. Último erro: NameError(\"name 'torch' is not defined\")\n",
      "Nenhum modelo ML disponível. Usando fallback lexicon (muito simples).\n",
      "Salvo: ..\\data\\news\\news_with_sentiment.parquet ..\\data\\news\\news_with_sentiment.csv\n",
      "                         avg_sentiment_score  news_count  positive_news_count  \\\n",
      "ticker_query year_month                                                         \n",
      "YDUQ3        2025-12                0.000000           2                    0   \n",
      "             2025-11               -0.071429          14                    0   \n",
      "WEGE3        2025-12                0.062500          16                    1   \n",
      "             2025-11                0.000000          10                    1   \n",
      "VIVT3        2025-12               -0.421053          19                    0   \n",
      "             2025-11                0.142857          14                    2   \n",
      "VIVA3        2025-12                0.000000           5                    0   \n",
      "             2025-11                0.000000           2                    0   \n",
      "VBBR3        2025-12                0.000000           9                    0   \n",
      "             2025-11                0.000000          15                    0   \n",
      "VAMO3        2025-12                0.181818          11                    2   \n",
      "             2025-11                0.280702          19                    8   \n",
      "VALE3        2025-12                0.200000          40                    8   \n",
      "             2025-11                0.108696          46                    8   \n",
      "USIM5        2025-12                0.000000           8                    0   \n",
      "\n",
      "                         negative_news_count  \n",
      "ticker_query year_month                       \n",
      "YDUQ3        2025-12                       0  \n",
      "             2025-11                       1  \n",
      "WEGE3        2025-12                       0  \n",
      "             2025-11                       1  \n",
      "VIVT3        2025-12                       8  \n",
      "             2025-11                       0  \n",
      "VIVA3        2025-12                       0  \n",
      "             2025-11                       0  \n",
      "VBBR3        2025-12                       0  \n",
      "             2025-11                       0  \n",
      "VAMO3        2025-12                       0  \n",
      "             2025-11                       3  \n",
      "VALE3        2025-12                       0  \n",
      "             2025-11                       3  \n",
      "USIM5        2025-12                       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaike\\AppData\\Local\\Temp\\ipykernel_17412\\508251517.py:46: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df['year_month'] = df['published_date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Main pipeline ----------------\n",
    "def main():\n",
    "    print(\"Iniciando pipeline de sentimento.\")\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        print(f\"Arquivo de notícias não encontrado: {INPUT_FILE}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_parquet(INPUT_FILE)\n",
    "    print(\"Loaded input:\", df.shape)\n",
    "\n",
    "    device = pick_device()\n",
    "    print(\"Device selecionado:\", device, \"(0 => gpu, -1 => cpu)\")\n",
    "\n",
    "    hf_token = os.environ.get(\"HF_TOKEN\", None)\n",
    "    pipe, model_name, label_map = try_load_pipeline(MODEL_CANDIDATES, device=device, use_auth_token=hf_token)\n",
    "\n",
    "    if pipe is None:\n",
    "        print(\"Nenhum modelo ML disponível. Usando fallback lexicon (muito simples).\")\n",
    "        # fallback lexicon aplicado a todos os títulos\n",
    "        text_col = \"title\" if \"title\" in df.columns else df.columns[0]\n",
    "        labels_scores = [tiny_lexicon_sentiment(x) for x in df[text_col].astype(str).tolist()]\n",
    "    else:\n",
    "        print(\"Executando inferência em batch com modelo:\", model_name)\n",
    "        text_col = \"title\" if \"title\" in df.columns else ( \"summary\" if \"summary\" in df.columns else df.columns[0] )\n",
    "        texts = df[text_col].astype(str).fillna(\"\").tolist()\n",
    "        labels_scores = batch_sentiment_inference(pipe, texts, batch_size=BATCH_SIZE, label_map=label_map)\n",
    "\n",
    "    labels, scores = zip(*labels_scores)\n",
    "    df[\"sentiment_label\"] = list(labels)\n",
    "    df[\"sentiment_score\"] = list(scores)\n",
    "    df[\"numeric_sentiment\"] = df[\"sentiment_label\"].apply(label_to_numeric)\n",
    "    df[\"sentiment_weighted\"] = df[\"numeric_sentiment\"] * df[\"sentiment_score\"].fillna(0.0)\n",
    "\n",
    "    # salvar parquet + csv\n",
    "    os.makedirs(NEWS_DIR, exist_ok=True)\n",
    "    df.to_parquet(OUTPUT_FILE_PARQUET, index=False)\n",
    "    df_to_csv = df.copy()\n",
    "    if \"published_date\" in df_to_csv.columns:\n",
    "        df_to_csv['published_date'] = pd.to_datetime(df_to_csv['published_date'], errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "    df_to_csv.to_csv(OUTPUT_FILE_CSV, index=False)\n",
    "    print(\"Salvo:\", OUTPUT_FILE_PARQUET, OUTPUT_FILE_CSV)\n",
    "\n",
    "    # agregação por ticker/mês (se dados disponíveis)\n",
    "    if \"published_date\" in df.columns and \"ticker_query\" in df.columns:\n",
    "        df['published_date'] = pd.to_datetime(df['published_date'], errors='coerce', utc=True)\n",
    "        df['year_month'] = df['published_date'].dt.to_period('M')\n",
    "        aggregation = df.groupby(['ticker_query','year_month']).agg(\n",
    "            avg_sentiment_score=('sentiment_weighted','mean'),\n",
    "            news_count=('title','count'),\n",
    "            positive_news_count=('numeric_sentiment', lambda s: (s==1).sum()),\n",
    "            negative_news_count=('numeric_sentiment', lambda s: (s==-1).sum())\n",
    "        ).sort_values(by=['ticker_query','year_month'], ascending=False)\n",
    "        print(aggregation.head(15))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95618f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "Torch import failed: No module named 'torch'\n",
      "Transformers: 4.57.3\n",
      "Carregando modelo teste (distilbert)...\n",
      "Erro carregando/rodando pipeline: <class 'NameError'> name 'torch' is not defined\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    print(\"Torch import failed:\", e)\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"Transformers:\", transformers.__version__)\n",
    "except Exception as e:\n",
    "    print(\"Transformers import failed:\", e)\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    print(\"Carregando modelo teste (distilbert)...\")\n",
    "    p = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english', device=-1)\n",
    "    print(\"Modelo carregado. Test inference:\", p(\"This is great\")[0])\n",
    "except Exception as e:\n",
    "    print(\"Erro carregando/rodando pipeline:\", type(e), e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "987dfd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando pysentimiento/bertweet-pt-sentiment\n",
      "pysentimiento/bertweet-pt-sentiment falhou: <class 'NameError'> name 'torch' is not defined\n",
      "Tentando cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
      "cardiffnlp/twitter-xlm-roberta-base-sentiment falhou: <class 'NameError'> name 'torch' is not defined\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# teste com modelo em pt (publico)\n",
    "for m in [\"pysentimiento/bertweet-pt-sentiment\",\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"]:\n",
    "    try:\n",
    "        print(\"Tentando\", m)\n",
    "        p = pipeline('sentiment-analysis', model=m, device=-1)  # use device=0 se GPU\n",
    "        print(m, \"-> ok. exemplo:\", p(\"A empresa divulgou lucro melhor que o esperado.\")[0])\n",
    "    except Exception as e:\n",
    "        print(m, \"falhou:\", type(e), e)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
