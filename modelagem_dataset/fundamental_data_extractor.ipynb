{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f730634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 14:36:43,157 [logging.log_init] INFO: LOGLEVEL=INFO\n"
     ]
    }
   ],
   "source": [
    "# fundamental_data_extractor.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import fundamentus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99144570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "\n",
    "# Diretório para salvar os dados\n",
    "DATA_DIR = \"data\"\n",
    "FUNDAMENTAL_DIR = os.path.join(DATA_DIR, \"fundamental\")\n",
    "os.makedirs(FUNDAMENTAL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0fdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tickers_from_csv(file_path: str) -> list:\n",
    "    \"\"\"Carrega a lista de tickers a partir de um arquivo CSV.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"Arquivo de tickers não encontrado em: {file_path}\")\n",
    "        return []\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Heurística para encontrar a coluna de tickers\n",
    "    if 'Ticker' in df.columns:\n",
    "        tickers = df['Ticker'].dropna().astype(str).tolist()\n",
    "    else:\n",
    "        tickers = df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "        \n",
    "    # Normaliza para o formato que `fundamentus` espera (ex: 'PETR4' sem '.SA')\n",
    "    tickers_normalized = [t.replace('.SA', '') for t in tickers]\n",
    "    logging.info(f\"{len(tickers_normalized)} tickers carregados de {file_path}\")\n",
    "    return tickers_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eda195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 14:36:43,230 [2232004078.load_tickers_from_csv] INFO: 97 tickers carregados de tickers_ibrx100_full.csv\n",
      "2025-10-16 14:36:43,232 [3659490165.get_fundamental_data] INFO: Iniciando a captura de dados fundamentalistas...\n",
      "Buscando dados fundamentalistas: 100%|██████████| 97/97 [00:07<00:00, 13.74it/s]\n",
      "2025-10-16 14:36:50,800 [3659490165.<module>] INFO: Dados fundamentalistas salvos em: data\\fundamental\\fundamentus_data.parquet\n",
      "2025-10-16 14:36:50,808 [3659490165.<module>] INFO: Dados fundamentalistas salvos também em: data\\fundamental\\fundamentus_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra dos Dados Coletados ---\n",
      "  ticker  Papel   Tipo       Empresa                    Setor  \\\n",
      "0  ALOS3  ALOS3     ON      ALLOS ON    Exploração de Imóveis   \n",
      "1  ABEV3  ABEV3     ON  AMBEV S/A ON                  Bebidas   \n",
      "2  ANIM3  ANIM3  ON NM   ANIMA ON NM                 Diversos   \n",
      "3  ASAI3  ASAI3  ON NM   ASSAI ON NM  Comércio e Distribuição   \n",
      "4  AURE3  AURE3  ON NM   AUREN ON NM         Energia Elétrica   \n",
      "\n",
      "                   Subsetor Cotacao Data_ult_cot Min_52_sem Max_52_sem  ...  \\\n",
      "0     Exploração de Imóveis   23.79   2025-10-14      16.48      25.86  ...   \n",
      "1  Cervejas e Refrigerantes   12.05   2025-10-14      10.52      14.29  ...   \n",
      "2     Serviços Educacionais    3.12   2025-10-14       1.49       4.44  ...   \n",
      "3                 Alimentos    8.19   2025-10-14       5.06      11.86  ...   \n",
      "4          Energia Elétrica   10.46   2025-10-14       7.34      11.06  ...   \n",
      "\n",
      "  Lucro_Liquido_12m Receita_Liquida_3m     EBIT_3m Lucro_Liquido_3m  \\\n",
      "0         737411000          697295000   351830000        201401000   \n",
      "1       14752300000        20090200000  3864470000       2717720000   \n",
      "2         140564000         1005340000   284927000          9539000   \n",
      "3         922000000        19002000000  1390000000        219000000   \n",
      "4        -700663000         2885530000   353291000       -615390000   \n",
      "\n",
      "  Cart_de_Credito Depositos Result_Int_Financ_12m Rec_Servicos_12m  \\\n",
      "0             NaN       NaN                   NaN              NaN   \n",
      "1             NaN       NaN                   NaN              NaN   \n",
      "2             NaN       NaN                   NaN              NaN   \n",
      "3             NaN       NaN                   NaN              NaN   \n",
      "4             NaN       NaN                   NaN              NaN   \n",
      "\n",
      "  Result_Int_Financ_3m Rec_Servicos_3m  \n",
      "0                  NaN             NaN  \n",
      "1                  NaN             NaN  \n",
      "2                  NaN             NaN  \n",
      "3                  NaN             NaN  \n",
      "4                  NaN             NaN  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "\n",
      "Dimensões do DataFrame: (97, 55)\n"
     ]
    }
   ],
   "source": [
    "# fundamental_data_extractor.py -> Função get_fundamental_data atualizada\n",
    "def get_fundamental_data(tickers: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Busca dados fundamentalistas para uma lista de tickers usando a biblioteca fundamentus.\n",
    "    Inclui uma etapa de sanitização para lidar com valores que são listas ou Series.\n",
    "    Retorna um único DataFrame com todos os dados.\n",
    "    \"\"\"\n",
    "    if not tickers:\n",
    "        logging.warning(\"A lista de tickers está vazia. Nenhum dado será buscado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_data = []\n",
    "    \n",
    "    logging.info(\"Iniciando a captura de dados fundamentalistas...\")\n",
    "    for ticker in tqdm(tickers, desc=\"Buscando dados fundamentalistas\"):\n",
    "        try:\n",
    "            data = fundamentus.get_detalhes_papel(ticker)\n",
    "            data['ticker'] = ticker\n",
    "            all_data.append(data)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Não foi possível obter dados para o ticker {ticker}. Erro: {e}\")\n",
    "            continue\n",
    "            \n",
    "    if not all_data:\n",
    "        logging.error(\"Nenhum dado fundamentalista foi capturado com sucesso.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- INÍCIO DA CORREÇÃO (AGORA MAIS ROBUSTA) ---\n",
    "    # Etapa de Sanitização: Converte valores que são listas, tuplas ou Series em strings.\n",
    "    sanitized_data = []\n",
    "    for company_data in all_data:\n",
    "        sanitized_item = {}\n",
    "        for key, value in company_data.items():\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                # Se o valor for uma lista, une seus elementos em uma única string\n",
    "                sanitized_item[key] = ' / '.join(map(str, value))\n",
    "            \n",
    "            # ADICIONADO: Verifica também se o valor é uma Series do pandas\n",
    "            elif isinstance(value, pd.Series):\n",
    "                # Converte a Series para uma lista de strings e depois une\n",
    "                sanitized_item[key] = ' / '.join(value.astype(str).tolist())\n",
    "                \n",
    "            else:\n",
    "                # Caso contrário, mantém o valor original\n",
    "                sanitized_item[key] = value\n",
    "        sanitized_data.append(sanitized_item)\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "    # Converte a lista SANITIZADA de dicionários em um DataFrame\n",
    "    df_fundamental = pd.DataFrame(sanitized_data)\n",
    "    \n",
    "    # Reordena as colunas para ter 'ticker' primeiro\n",
    "    if 'ticker' in df_fundamental.columns:\n",
    "        cols = ['ticker'] + [col for col in df_fundamental.columns if col != 'ticker']\n",
    "        df_fundamental = df_fundamental[cols]\n",
    "        \n",
    "    return df_fundamental\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Carregar os tickers do arquivo CSV gerado anteriormente\n",
    "    tickers_csv_path = \"tickers_ibrx100_full.csv\"\n",
    "    ibrx_tickers = load_tickers_from_csv(tickers_csv_path)\n",
    "    \n",
    "    # 2. Buscar os dados fundamentalistas\n",
    "    df_fund = get_fundamental_data(ibrx_tickers)\n",
    "    \n",
    "    # 3. Salvar os resultados\n",
    "    if not df_fund.empty:\n",
    "        output_path_parquet = os.path.join(FUNDAMENTAL_DIR, \"fundamentus_data.parquet\")\n",
    "        output_path_csv = os.path.join(FUNDAMENTAL_DIR, \"fundamentus_data.csv\")\n",
    "        \n",
    "        # Salva em Parquet (preferencial)\n",
    "        df_fund.to_parquet(output_path_parquet, index=False)\n",
    "        logging.info(f\"Dados fundamentalistas salvos em: {output_path_parquet}\")\n",
    "        \n",
    "        # Salva também em CSV para fácil visualização\n",
    "        df_fund.to_csv(output_path_csv, index=False)\n",
    "        logging.info(f\"Dados fundamentalistas salvos também em: {output_path_csv}\")\n",
    "        \n",
    "        print(\"\\n--- Amostra dos Dados Coletados ---\")\n",
    "        print(df_fund.head())\n",
    "        print(f\"\\nDimensões do DataFrame: {df_fund.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_aurum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
